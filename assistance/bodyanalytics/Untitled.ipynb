{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4495f741-0be2-499b-a2b4-8ce7928fbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class EnhancedExerciseHierarchicalDataset(Dataset):\n",
    "    def __init__(self, data_dir, exercices_points, grouped_sports, max_seq_len=45,\n",
    "                 augment=False, validate_physics=True): # Removed base_feature_dim here\n",
    "        self.augment = augment\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.validate_physics = validate_physics\n",
    "        self.data_dir = data_dir\n",
    "        self.exercise_names = []\n",
    "\n",
    "        # Cache des dimensions par exercice\n",
    "        self.feature_cache = {}\n",
    "        self.exercises_points = exercices_points\n",
    "        self.grouped_sports = grouped_sports # Keep grouped_sports for mapping\n",
    "\n",
    "        # Construction des mappings et chargement avec validation (dynamic)\n",
    "        self._build_mappings_dynamic()\n",
    "\n",
    "        # Determine the maximum feature dimension across the dynamically loaded exercises\n",
    "        self.max_feature_dim = self._calculate_max_feature_dim(self.present_exercises)\n",
    "\n",
    "        self._load_samples_enhanced()\n",
    "\n",
    "        if validate_physics:\n",
    "            self._validate_dataset_quality()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "    def _calculate_max_feature_dim(self, present_exercises):\n",
    "        \"\"\"Calculates the maximum feature dimension across the present exercises.\"\"\"\n",
    "        max_dim = 0\n",
    "        for exercise_name in present_exercises:\n",
    "            if exercise_name in self.exercises_points:\n",
    "                num_points = len(self.exercises_points[exercise_name])\n",
    "                # CoordonnÃ©es 3D + Angles + Distances + Vitesses + AccÃ©lÃ©rations\n",
    "                current_dim = num_points * 3 + 3 + 2 + num_points * 3 + num_points * 3\n",
    "                max_dim = max(max_dim, current_dim)\n",
    "        # If no exercises are present, return a default or handle appropriately\n",
    "        return max_dim if max_dim > 0 else 0\n",
    "\n",
    "\n",
    "    def _validate_dataset_quality(self):\n",
    "      \"\"\"Valide les échantillons chargés (placeholder simple).\"\"\"\n",
    "      # Ici, tu peux ajouter des vérifications avancées, par par exemple :\n",
    "      valid_samples = []\n",
    "      valid_labels = []\n",
    "      valid_groups = []\n",
    "      valid_exercise_names = []\n",
    "      for i, path in enumerate(self.samples):\n",
    "          try:\n",
    "              arr = np.load(path, mmap_mode='r')\n",
    "              # Exemple : on vérifie qu'il n'y a pas de NaN\n",
    "              if not np.isnan(arr).any() and not np.isinf(arr).any():\n",
    "                  valid_samples.append(path)\n",
    "                  valid_labels.append(self.labels[i])\n",
    "                  valid_groups.append(self.groups[i])\n",
    "                  valid_exercise_names.append(self.exercise_names[i])\n",
    "          except Exception as e:\n",
    "              print(f\"Fichier corrompu ou illisible: {path} ({e})\")\n",
    "      print(f\"Après validation: {len(valid_samples)} séquences valides / {len(self.samples)}\")\n",
    "      self.samples = valid_samples\n",
    "      self.labels = valid_labels\n",
    "      self.groups = valid_groups\n",
    "      self.exercise_names = valid_exercise_names\n",
    "\n",
    "\n",
    "    def _build_mappings_dynamic(self):\n",
    "        \"\"\"Construit les mappings exercice <-> groupe dynamiquement basés sur les fichiers prétraités\"\"\"\n",
    "        self.present_exercises = []\n",
    "        print(f\"Scanning directory for preprocessed data: {self.data_dir}\")\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f\"Data directory not found: {self.data_dir}\")\n",
    "            self.exercise_to_idx = {}\n",
    "            self.idx_to_exercise = {}\n",
    "            self.exercise_to_group = {}\n",
    "            self.group_to_idx = {}\n",
    "            self.idx_to_group = {}\n",
    "            return\n",
    "\n",
    "        # Determine which exercises have preprocessed data and are in a defined group\n",
    "        exercises_with_data_and_group = []\n",
    "        for exercise_name in self.exercises_points:\n",
    "            ex_dir = os.path.join(self.data_dir, exercise_name)\n",
    "            if os.path.isdir(ex_dir):\n",
    "                # Check if there is at least one .npy file in the directory\n",
    "                npy_files = list(Path(ex_dir).glob('*.npy'))\n",
    "                # Check if the exercise is in any defined group\n",
    "                is_in_a_group = any(exercise_name in exercises for exercises in self.grouped_sports.values())\n",
    "\n",
    "                if npy_files and is_in_a_group:\n",
    "                    exercises_with_data_and_group.append(exercise_name)\n",
    "\n",
    "        self.present_exercises = sorted(exercises_with_data_and_group)\n",
    "\n",
    "        print(f\"Found {len(self.present_exercises)} present exercises with data and group mapping.\")\n",
    "\n",
    "        # Mapping exercice -> index (only for present exercises)\n",
    "        self.exercise_to_idx = {ex: i for i, ex in enumerate(self.present_exercises)}\n",
    "        self.idx_to_exercise = {i: ex for ex, i in self.exercise_to_idx.items()}\n",
    "        print(f\"exercise_to_idx (dynamic): {self.exercise_to_idx}\")\n",
    "        # print(f\"idx_to_exercise (dynamic): {self.idx_to_exercise}\") # Avoid printing potentially long dict\n",
    "\n",
    "        # Mapping exercice -> groupe (with verification against present exercises)\n",
    "        self.exercise_to_group = {}\n",
    "        for group_name, exercises in self.grouped_sports.items():\n",
    "            for ex in exercises:\n",
    "                if ex in self.exercise_to_idx: # Check if exercise is present and mapped\n",
    "                    self.exercise_to_group[ex] = group_name\n",
    "        print(f\"exercise_to_group (dynamic): {self.exercise_to_group}\")\n",
    "\n",
    "        # Mapping groupe -> index (only for groups with present exercises)\n",
    "        present_groups = sorted(list(set(self.exercise_to_group.values())))\n",
    "        self.group_to_idx = {g: i for i, g in enumerate(present_groups)}\n",
    "        self.idx_to_group = {i: g for g, i in self.group_to_idx.items()}\n",
    "        print(f\"group_to_idx (dynamic): {self.group_to_idx}\")\n",
    "        # print(f\"idx_to_group (dynamic): {self.idx_to_group}\") # Avoid printing potentially long dict\n",
    "\n",
    "\n",
    "    def _load_samples_enhanced(self):\n",
    "        \"\"\"Charge les échantillons avec validation des chemins\"\"\"\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.groups = []\n",
    "        self.exercise_names = []\n",
    "        loaded_count = 0\n",
    "        skipped_count = 0\n",
    "\n",
    "        if not self.present_exercises:\n",
    "            print(\"No present exercises found with data and group. Skipping sample loading.\")\n",
    "            return\n",
    "\n",
    "        for ex in self.present_exercises:\n",
    "            ex_dir = os.path.join(self.data_dir, ex)\n",
    "            # This directory should exist based on _build_mappings_dynamic, but double-check\n",
    "            if not os.path.isdir(ex_dir):\n",
    "                print(f\"Warning: Directory unexpectedly missing for present exercise: {ex_dir}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                for fname in os.listdir(ex_dir):\n",
    "                    if fname.endswith('.npy'):\n",
    "                        path = os.path.join(ex_dir, fname)\n",
    "                        if not os.path.exists(path):\n",
    "                            print(f\"Fichier manquant: {path}\")\n",
    "                            skipped_count += 1\n",
    "                            continue\n",
    "\n",
    "                        # Basic check for file size to quickly filter out potentially empty files\n",
    "                        if os.path.getsize(path) < 100: # Arbitrary small threshold\n",
    "                            print(f\"Skipping potentially empty file: {path}\")\n",
    "                            skipped_count += 1\n",
    "                            continue\n",
    "\n",
    "                        self.samples.append(path)\n",
    "                        # Use the dynamically created exercise_to_idx\n",
    "                        # Ensure the exercise is still in exercise_to_idx (should be based on _build_mappings)\n",
    "                        if ex in self.exercise_to_idx:\n",
    "                             self.labels.append(self.exercise_to_idx[ex])\n",
    "                        else:\n",
    "                            # This case should ideally not be reached with the updated _build_mappings\n",
    "                            print(f\"Warning: Exercise {ex} in samples but not in exercise_to_idx. Skipping sample.\")\n",
    "                            skipped_count += 1\n",
    "                            self.samples.pop() # Remove the appended path\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        # Use the dynamically created group_to_idx and exercise_to_group\n",
    "                        # Ensure the exercise is still in exercise_to_group (should be based on _build_mappings)\n",
    "                        if ex in self.exercise_to_group:\n",
    "                            self.groups.append(self.group_to_idx[self.exercise_to_group[ex]])\n",
    "                            self.exercise_names.append(ex)\n",
    "                            loaded_count += 1\n",
    "                        else:\n",
    "                            # This case should ideally not be reached with the updated _build_mappings\n",
    "                            print(f\"Warning: Exercise {ex} in samples but not in exercise_to_group. Skipping sample.\")\n",
    "                            # Remove the appended path and label as well\n",
    "                            self.samples.pop()\n",
    "                            self.labels.pop()\n",
    "                            skipped_count += 1\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing directory {ex_dir}: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Finished loading samples. Loaded {loaded_count} samples, skipped {skipped_count}.\")\n",
    "\n",
    "\n",
    "    def _calculate_expected_features(self, exercise_name):\n",
    "        \"\"\"Calculates the expected feature dimension for a given exercise.\"\"\"\n",
    "        if exercise_name not in self.exercises_points:\n",
    "            # Fallback or error handling if exercise is not in the points mapping\n",
    "            print(f\"Warning: Exercise '{exercise_name}' not found in exercises_points.\")\n",
    "            # Return a default or the max dimension\n",
    "            return self.max_feature_dim # Use max_feature_dim as a safe fallback\n",
    "\n",
    "\n",
    "        num_points = len(self.exercises_points[exercise_name])\n",
    "        base_features = num_points * 3\n",
    "\n",
    "        # Features du prétraitement amélioré (Angles, Distances, Vitesses, Accélérations)\n",
    "        # Make sure this calculation matches the actual feature generation in preprocessor\n",
    "        angles = 3  # coude, genou, torse\n",
    "        distances = 2  # distances relatives\n",
    "        dynamics = base_features * 2  # vitesses + accélérations (3D * 2 for vel+acc)\n",
    "\n",
    "        total_features = base_features + angles + distances + dynamics\n",
    "        return total_features\n",
    "\n",
    "    def _extract_exercise_name(self, file_path):\n",
    "        \"\"\"Extrait le nom d'exercice depuis le chemin de fichier\"\"\"\n",
    "        path_parts = os.path.normpath(file_path).split(os.sep)\n",
    "        for part in path_parts:\n",
    "            if part in self.exercises_points:\n",
    "                return part\n",
    "        return \"unknown\"\n",
    "\n",
    "    def _validate_sample_quality(self, seq, exercise_name):\n",
    "        \"\"\"Valide la qualité d'un échantillon selon les critères physiques\"\"\"\n",
    "        if seq.shape[0] == 0:\n",
    "            return False\n",
    "\n",
    "        # Vérification NaN/Inf\n",
    "        if np.isnan(seq).any() or np.isinf(seq).any():\n",
    "            return False\n",
    "\n",
    "        # Vérification variance\n",
    "        variance = np.var(seq, axis=0)\n",
    "        static_ratio = (variance < 1e-6).sum() / seq.shape[1]\n",
    "\n",
    "        return static_ratio < 0.3  # Moins de 30% de features statiques\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Load the numpy array\n",
    "            seq_np = np.load(self.samples[idx], mmap_mode='r', allow_pickle=False)\n",
    "\n",
    "            # Ensure the data is float32 and handle potential non-finite values after loading\n",
    "            seq_np = seq_np.astype(np.float32)\n",
    "            if np.isnan(seq_np).any() or np.isinf(seq_np).any():\n",
    "                 print(f\"Warning: NaN or Inf found in {self.samples[idx]} after loading. Skipping.\")\n",
    "                 return None # Skip this sample\n",
    "\n",
    "            seq = torch.from_numpy(seq_np)\n",
    "\n",
    "            exercise_name = self.exercise_names[idx]\n",
    "            # We no longer need expected_features per sample for padding in _standardize_sequence_enhanced\n",
    "\n",
    "            # Validation physique if enabled\n",
    "            if self.validate_physics and not self._validate_sample_quality(seq.numpy(), exercise_name):\n",
    "                print(f\"Warning: Sample {self.samples[idx]} failed quality validation. Skipping.\")\n",
    "                return None\n",
    "\n",
    "\n",
    "            # Adaptive standardization using the global max_feature_dim\n",
    "            seq = self._standardize_sequence_enhanced(seq, self.max_feature_dim)\n",
    "\n",
    "\n",
    "            if self.augment:\n",
    "                seq = self.augment_sequence(seq)\n",
    "\n",
    "            return (\n",
    "                seq.to(device),\n",
    "                torch.tensor(self.labels[idx], dtype=torch.long).to(device),\n",
    "                torch.tensor(self.groups[idx], dtype=torch.long).to(device)\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading or processing {self.samples[idx]}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _standardize_sequence_enhanced(self, seq, target_feature_dim):\n",
    "        \"\"\"Adaptive standardization to a target feature dimension.\"\"\"\n",
    "        # Feature adjustment\n",
    "        if seq.shape[1] < target_feature_dim:\n",
    "            padding = target_feature_dim - seq.shape[1]\n",
    "            seq = torch.nn.functional.pad(seq, (0, padding), mode='constant', value=0)\n",
    "        elif seq.shape[1] > target_feature_dim:\n",
    "            seq = seq[:, :target_feature_dim]\n",
    "\n",
    "        # Temporal adjustment\n",
    "        if seq.shape[0] > self.max_seq_len:\n",
    "            seq = seq[:self.max_seq_len]\n",
    "        elif seq.shape[0] < self.max_seq_len:\n",
    "            padding = self.max_seq_len - seq.shape[0]\n",
    "            seq = torch.nn.functional.pad(seq, (0, 0, 0, padding), mode='constant', value=0)\n",
    "\n",
    "        return seq\n",
    "\n",
    "    def augment_sequence(self, seq):\n",
    "      \"\"\"Enhanced data augmentation\"\"\"\n",
    "      # Controlled Jitter\n",
    "      if random.random() < 0.5 and seq.numel() > 0: # Added check for empty tensor\n",
    "          noise_level = 0.02 * torch.std(seq)\n",
    "          seq += torch.randn_like(seq) * noise_level\n",
    "\n",
    "      # Adaptive Scaling\n",
    "      if random.random() < 0.5 and seq.numel() > 0: # Added check for empty tensor\n",
    "          scale = random.uniform(0.95, 1.05)\n",
    "          seq *= scale\n",
    "\n",
    "      # Selective Masking with PyTorch\n",
    "      if random.random() < 0.3 and seq.numel() > 0: # Added check for empty tensor\n",
    "          mask = (torch.rand_like(seq) > 0.15).float()\n",
    "          mean_val = torch.mean(seq) if seq.numel() > 0 else 0.0 # Handle empty tensor mean\n",
    "          seq = seq * mask + (1 - mask) * mean_val\n",
    "\n",
    "      # Temporal Permutation with PyTorch\n",
    "      if random.random() < 0.2 and seq.size(0) > 5: # Ensure enough frames for splitting\n",
    "          seq_len = seq.size(0)\n",
    "          try:\n",
    "              split_indices = sorted(random.sample(range(1, seq_len), random.randint(1, min(3, seq_len - 1))))\n",
    "              split_sizes = [split_indices[0]]\n",
    "              for i in range(len(split_indices) - 1):\n",
    "                  split_sizes.append(split_indices[i+1] - split_indices[i])\n",
    "              split_sizes.append(seq_len - split_indices[-1])\n",
    "              segments = torch.split(seq, split_sizes)\n",
    "\n",
    "              indices = torch.randperm(len(segments))\n",
    "              seq = torch.cat([segments[i] for i in indices], dim=0)[:seq_len] # Ensure length is preserved\n",
    "          except ValueError as e:\n",
    "               print(f\"Warning: Temporal permutation failed for a sample. {e}\") # Log error\n",
    "\n",
    "      return seq\n",
    "\n",
    "class AdaptiveExerciseStandards:\n",
    "    \"\"\"\n",
    "    Système de standards d'exercices adaptatifs avec zones de tolérance dynamiques\n",
    "    et apprentissage continu basé sur le profil utilisateur.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_profile=None):\n",
    "        self.user_profile = user_profile or {}\n",
    "        self.adaptation_history = []\n",
    "        self.performance_metrics = {}\n",
    "\n",
    "        # Standards biomécaniques adaptatifs\n",
    "        self.exercise_standards = {\n",
    "            \"squat\": {\n",
    "                'biomechanical_parameters': {\n",
    "                    'knee_angle_min': {'novice': 80, 'intermediate': 75, 'expert': 70},\n",
    "                    'knee_angle_max': {'novice': 120, 'intermediate': 115, 'expert': 110},\n",
    "                    'back_straight_threshold': {'novice': 0.15, 'intermediate': 0.12, 'expert': 0.08},\n",
    "                    'hip_mobility_index': {'novice': 0.6, 'intermediate': 0.75, 'expert': 0.9},\n",
    "                    'ankle_dorsiflexion': {'novice': 15, 'intermediate': 20, 'expert': 25},\n",
    "                    'coordination_score': {'novice': 0.5, 'intermediate': 0.7, 'expert': 0.9},\n",
    "                    'stability_coefficient': {'novice': 0.6, 'intermediate': 0.8, 'expert': 0.95}\n",
    "                },\n",
    "                'tolerance_zones': {\n",
    "                    'novice': 0.20,      # ±20% de tolérance\n",
    "                    'intermediate': 0.12, # ±12% de tolérance\n",
    "                    'expert': 0.05       # ±5% de tolérance\n",
    "                },\n",
    "                'adaptive_corrections': {\n",
    "                    'novice': {\n",
    "                        'knee_too_closed': \"Descendez jusqu'à ce que vos hanches soient au niveau de vos genoux. Prenez votre temps pour maîtriser le mouvement.\",\n",
    "                        'knee_too_open': \"Remontez légèrement, évitez de descendre trop bas pour commencer.\",\n",
    "                        'back_not_straight': \"Gardez la poitrine haute et regardez droit devant. Imaginez un mur derrière votre dos.\",\n",
    "                        'progression_tip': \"Excellent progrès ! Continuez à travailler votre mobilité de cheville.\"\n",
    "                    },\n",
    "                    'intermediate': {\n",
    "                        'knee_too_closed': \"Travaillez votre mobilité de cheville et descendez plus profondément en gardant les talons au sol.\",\n",
    "                        'knee_too_open': \"Contrôlez mieux la descente, la profondeur optimale se situe à 90° aux genoux.\",\n",
    "                        'back_not_straight': \"Renforcez votre gainage et initiez le mouvement par les hanches plutôt que les genoux.\",\n",
    "                        'progression_tip': \"Bonne technique ! Travaillez maintenant la coordination hanche-genou.\"\n",
    "                    },\n",
    "                    'expert': {\n",
    "                        'knee_too_closed': \"Optimisez votre patron moteur : initiation hanche-genou coordinée avec activation préalable du tronc.\",\n",
    "                        'knee_too_open': \"Ajustez la profondeur selon votre morphologie et vos objectifs de performance.\",\n",
    "                        'back_not_straight': \"Travaillez la stabilité dynamique du tronc en intégrant des charges asymétriques.\",\n",
    "                        'progression_tip': \"Technique maîtrisée ! Explorez les variations avancées.\"\n",
    "                    }\n",
    "                },\n",
    "                'fatigue_adjustments': {\n",
    "                    'light': 1.0,    # Pas d'ajustement\n",
    "                    'moderate': 1.15, # +15% de tolérance\n",
    "                    'high': 1.30     # +30% de tolérance\n",
    "                }\n",
    "            },\n",
    "\n",
    "            \"push-up\": {\n",
    "                'biomechanical_parameters': {\n",
    "                    'elbow_angle_min': {'novice': 50, 'intermediate': 45, 'expert': 40},\n",
    "                    'elbow_angle_max': {'novice': 95, 'intermediate': 90, 'expert': 85},\n",
    "                    'body_alignment_threshold': {'novice': 0.20, 'intermediate': 0.15, 'expert': 0.10},\n",
    "                    'scapular_stability': {'novice': 0.5, 'intermediate': 0.7, 'expert': 0.9},\n",
    "                    'core_activation': {'novice': 0.6, 'intermediate': 0.8, 'expert': 0.95},\n",
    "                    'movement_tempo': {'novice': 2.0, 'intermediate': 1.5, 'expert': 1.0},\n",
    "                    'range_of_motion': {'novice': 0.7, 'intermediate': 0.85, 'expert': 1.0}\n",
    "                },\n",
    "                'tolerance_zones': {\n",
    "                    'novice': 0.25,\n",
    "                    'intermediate': 0.15,\n",
    "                    'expert': 0.08\n",
    "                },\n",
    "                'adaptive_corrections': {\n",
    "                    'novice': {\n",
    "                        'arms_too_wide': \"Rapprochez vos mains et gardez les coudes près du corps. Commencez sur les genoux si nécessaire.\",\n",
    "                        'not_low_enough': \"Descendez progressivement en contrôlant le mouvement. L'amplitude viendra avec la pratique.\",\n",
    "                        'body_not_straight': \"Contractez les abdominaux et gardez le corps rigide comme une planche.\",\n",
    "                        'progression_tip': \"Excellent effort ! Votre stabilité s'améliore séance après séance.\"\n",
    "                    },\n",
    "                    'intermediate': {\n",
    "                        'arms_too_wide': \"Optimisez l'angle des coudes à 45° pour un meilleur recrutement musculaire.\",\n",
    "                        'not_low_enough': \"Travaillez l'amplitude complète en touchant presque le sol avec la poitrine.\",\n",
    "                        'body_not_straight': \"Renforcez la chaîne postérieure et maintenez l'alignement tête-bassin.\",\n",
    "                        'progression_tip': \"Bonne forme ! Intégrez maintenant des variations temporelles.\"\n",
    "                    },\n",
    "                    'expert': {\n",
    "                        'arms_too_wide': \"Ajustez finement l'angle selon vos objectifs : force (coudes serrés) ou volume (45°).\",\n",
    "                        'not_low_enough': \"Exploitez le cycle étirement-raccourcissement en pause isométrique en bas.\",\n",
    "                        'body_not_straight': \"Travaillez la stabilité anti-extension avec des charges externes.\",\n",
    "                        'progression_tip': \"Technique exemplaire ! Expérimentez les variations unipodales.\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "\n",
    "            \"deadlift\": {\n",
    "                'biomechanical_parameters': {\n",
    "                    'back_straight_threshold': {'novice': 0.15, 'intermediate': 0.10, 'expert': 0.05},\n",
    "                    'hip_angle_min': {'novice': 35, 'intermediate': 30, 'expert': 25},\n",
    "                    'hip_angle_max': {'novice': 180, 'intermediate': 180, 'expert': 180},\n",
    "                    'knee_tracking': {'novice': 0.6, 'intermediate': 0.8, 'expert': 0.95},\n",
    "                    'bar_path_deviation': {'novice': 3.0, 'intermediate': 2.0, 'expert': 1.0},\n",
    "                    'hip_hinge_ratio': {'novice': 0.6, 'intermediate': 0.8, 'expert': 0.9},\n",
    "                    'lockout_timing': {'novice': 1.5, 'intermediate': 1.2, 'expert': 1.0}\n",
    "                },\n",
    "                'tolerance_zones': {\n",
    "                    'novice': 0.22,\n",
    "                    'intermediate': 0.14,\n",
    "                    'expert': 0.06\n",
    "                },\n",
    "                'adaptive_corrections': {\n",
    "                    'novice': {\n",
    "                        'back_not_straight': \"Gardez la poitrine haute et les épaules en arrière. Commencez avec une barre surélevée si nécessaire.\",\n",
    "                        'hips_too_low': \"Remontez les hanches, le deadlift n'est pas un squat. Poussez les hanches vers l'arrière.\",\n",
    "                        'knees_not_aligned': \"Gardez les genoux dans l'axe des pieds, poussez le sol avec vos talons.\",\n",
    "                        'progression_tip': \"Bon travail ! Votre patron de hanche s'améliore.\"\n",
    "                    },\n",
    "                    'intermediate': {\n",
    "                        'back_not_straight': \"Travaillez la mobilité thoracique et renforcez les érecteurs du rachis.\",\n",
    "                        'hips_too_low': \"Optimisez l'angle de départ selon votre morphologie (longueur fémur/tibia).\",\n",
    "                        'knees_not_aligned': \"Renforcez les moyens fessiers et travaillez la stabilité frontale.\",\n",
    "                        'progression_tip': \"Excellente progression ! Votre technique se stabilise.\"\n",
    "                    },\n",
    "                    'expert': {\n",
    "                        'back_not_straight': \"Peaufinez la pré-tension du système et l'activation séquentielle des chaînes.\",\n",
    "                        'hips_too_low': \"Ajustez selon la variante : conventional, sumo ou trap bar.\",\n",
    "                        'knees_not_aligned': \"Optimisez la stratégie neuromusculaire selon vos points faibles.\",\n",
    "                        'progression_tip': \"Maîtrise technique ! Explorez les variations avancées.\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Métriques de progression\n",
    "        self.progression_tracking = {\n",
    "            'consistency_score': 0.0,\n",
    "            'improvement_rate': 0.0,\n",
    "            'technique_stability': 0.0,\n",
    "            'adaptation_speed': 0.0\n",
    "        }\n",
    "\n",
    "    def get_user_level(self):\n",
    "        \"\"\"Détermine le niveau de l'utilisateur basé sur l'historique et les performances.\"\"\"\n",
    "        if not self.user_profile:\n",
    "            return 'novice'\n",
    "\n",
    "        experience_months = self.user_profile.get('experience_months', 0)\n",
    "        consistency_score = self.progression_tracking.get('consistency_score', 0)\n",
    "        technique_stability = self.progression_tracking.get('technique_stability', 0)\n",
    "\n",
    "        # Algorithme de classification adaptatif\n",
    "        if experience_months >= 24 and consistency_score >= 0.8 and technique_stability >= 0.85:\n",
    "            return 'expert'\n",
    "        elif experience_months >= 6 and consistency_score >= 0.6 and technique_stability >= 0.7:\n",
    "            return 'intermediate'\n",
    "        else:\n",
    "            return 'novice'\n",
    "\n",
    "    def calculate_dynamic_thresholds(self, exercise, user_level, fatigue_state='light'):\n",
    "        \"\"\"Calcule les seuils adaptatifs en temps réel.\"\"\"\n",
    "        base_params = self.exercise_standards[exercise]['biomechanical_parameters']\n",
    "        tolerance = self.exercise_standards[exercise]['tolerance_zones'][user_level]\n",
    "        fatigue_factor = self.exercise_standards[exercise]['fatigue_adjustments'][fatigue_state]\n",
    "\n",
    "        adjusted_thresholds = {}\n",
    "        for param, values in base_params.items():\n",
    "            if isinstance(values, dict):\n",
    "                base_value = values[user_level]\n",
    "                adjusted_tolerance = tolerance * fatigue_factor\n",
    "                adjusted_thresholds[param] = {\n",
    "                    'target': base_value,\n",
    "                    'min': base_value * (1 - adjusted_tolerance),\n",
    "                    'max': base_value * (1 + adjusted_tolerance),\n",
    "                    'tolerance': adjusted_tolerance\n",
    "                }\n",
    "\n",
    "        return adjusted_thresholds\n",
    "\n",
    "    def get_adaptive_correction(self, exercise, error_type, user_level, performance_history=None):\n",
    "        \"\"\"Génère une correction adaptée au niveau et à l'historique de l'utilisateur.\"\"\"\n",
    "        corrections = self.exercise_standards[exercise]['adaptive_corrections'][user_level]\n",
    "\n",
    "        base_correction = corrections.get(error_type, \"Ajustez votre technique selon les indications.\")\n",
    "\n",
    "        # Ajustement contextuel basé sur l'historique\n",
    "        if performance_history:\n",
    "            recent_errors = performance_history.get('recent_errors', [])\n",
    "            if error_type in recent_errors[-3:]:  # Erreur récurrente\n",
    "                context_prefix = \"Erreur fréquente détectée : \"\n",
    "                if user_level == 'novice':\n",
    "                    context_prefix += \"Concentrez-vous particulièrement sur ce point. \"\n",
    "                elif user_level == 'intermediate':\n",
    "                    context_prefix += \"Travaillez spécifiquement cet aspect entre les séances. \"\n",
    "                else:\n",
    "                    context_prefix += \"Analysez votre patron moteur pour cette compensation. \"\n",
    "\n",
    "                return context_prefix + base_correction\n",
    "\n",
    "        return base_correction\n",
    "\n",
    "    def update_adaptation_history(self, exercise, performance_data, user_feedback=None):\n",
    "        \"\"\"Met à jour l'historique d'adaptation pour l'apprentissage continu.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "\n",
    "        adaptation_entry = {\n",
    "            'timestamp': timestamp,\n",
    "            'exercise': exercise,\n",
    "            'performance': performance_data,\n",
    "            'user_feedback': user_feedback,\n",
    "            'corrections_applied': performance_data.get('corrections', []),\n",
    "            'improvement_detected': self._detect_improvement(exercise, performance_data)\n",
    "        }\n",
    "\n",
    "        self.adaptation_history.append(adaptation_entry)\n",
    "        self._update_progression_metrics(exercise, performance_data)\n",
    "\n",
    "        # Limite la taille de l'historique\n",
    "        if len(self.adaptation_history) > 1000:\n",
    "            self.adaptation_history = self.adaptation_history[-800:]\n",
    "\n",
    "    def _detect_improvement(self, exercise, current_performance):\n",
    "        \"\"\"Détecte l'amélioration basée sur l'historique récent.\"\"\"\n",
    "        recent_sessions = [entry for entry in self.adaptation_history[-10:]\n",
    "                          if entry['exercise'] == exercise]\n",
    "\n",
    "        if len(recent_sessions) < 3:\n",
    "            return False\n",
    "\n",
    "        # Analyse de tendance simple\n",
    "        recent_scores = [session['performance'].get('overall_score', 0)\n",
    "                        for session in recent_sessions]\n",
    "        current_score = current_performance.get('overall_score', 0)\n",
    "\n",
    "        return current_score > np.mean(recent_scores) + np.std(recent_scores)\n",
    "\n",
    "    def _update_progression_metrics(self, exercise, performance_data):\n",
    "        \"\"\"Met à jour les métriques de progression globales.\"\"\"\n",
    "        # Implémentation simplifiée des métriques de progression\n",
    "        overall_score = performance_data.get('overall_score', 0)\n",
    "\n",
    "        if exercise not in self.performance_metrics:\n",
    "            self.performance_metrics[exercise] = []\n",
    "\n",
    "        self.performance_metrics[exercise].append(overall_score)\n",
    "\n",
    "        # Calcul de la consistance (écart-type inversé)\n",
    "        if len(self.performance_metrics[exercise]) >= 5:\n",
    "            scores = self.performance_metrics[exercise][-10:]\n",
    "            self.progression_tracking['consistency_score'] = max(0, 1 - np.std(scores) / max(np.mean(scores), 0.1))\n",
    "\n",
    "            # Taux d'amélioration (pente de régression)\n",
    "            if len(scores) >= 5:\n",
    "                x = np.arange(len(scores))\n",
    "                slope, _ = np.polyfit(x, scores, 1)\n",
    "                self.progression_tracking['improvement_rate'] = max(0, slope)\n",
    "\n",
    "    def generate_scoring_feedback(self, exercise, performance_score, user_level):\n",
    "        \"\"\"Génère un feedback graduel basé sur le score de performance.\"\"\"\n",
    "        if performance_score >= 95:\n",
    "            level = \"Excellent\"\n",
    "            message = f\"Performance exceptionnelle ! Technique maîtrisée au niveau {user_level}.\"\n",
    "        elif performance_score >= 85:\n",
    "            level = \"Très bon\"\n",
    "            message = f\"Très bonne exécution. Quelques ajustements mineurs pour la perfection.\"\n",
    "        elif performance_score >= 70:\n",
    "            level = \"Bon\"\n",
    "            message = f\"Bonne base technique. Continuez à travailler les points spécifiques.\"\n",
    "        elif performance_score >= 50:\n",
    "            level = \"Moyen\"\n",
    "            message = f\"Technique en développement. Concentrez-vous sur les fondamentaux.\"\n",
    "        else:\n",
    "            level = \"À améliorer\"\n",
    "            message = f\"Technique à retravailler. Prenez le temps de maîtriser les bases.\"\n",
    "\n",
    "        return {\n",
    "            'level': level,\n",
    "            'score': performance_score,\n",
    "            'message': message,\n",
    "            'next_focus': self._get_next_focus(exercise, performance_score, user_level)\n",
    "        }\n",
    "\n",
    "    def _get_next_focus(self, exercise, score, user_level):\n",
    "        \"\"\"Suggère le prochain point d'attention selon le niveau et le score.\"\"\"\n",
    "        focus_map = {\n",
    "            'squat': {\n",
    "                'novice': ['mobilité cheville', 'gainage de base', 'patron de mouvement'],\n",
    "                'intermediate': ['coordination hanche-genou', 'charge progressive', 'variations'],\n",
    "                'expert': ['optimisation biomécanique', 'variations avancées', 'performance']\n",
    "            },\n",
    "            'push-up': {\n",
    "                'novice': ['stabilité scapulaire', 'force de base', 'amplitude progressive'],\n",
    "                'intermediate': ['variations d\\'angle', 'tempo contrôlé', 'unilatéral'],\n",
    "                'expert': ['plyométrie', 'charges externes', 'patterns complexes']\n",
    "            },\n",
    "            'deadlift': {\n",
    "                'novice': ['patron de hanche', 'position de départ', 'mobilité'],\n",
    "                'intermediate': ['timing coordination', 'variations techniques', 'charge'],\n",
    "                'expert': ['optimisation morphologique', 'spécialisation', 'performance']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        exercise_focuses = focus_map.get(exercise, {}).get(user_level, ['technique générale'])\n",
    "        score_index = min(len(exercise_focuses) - 1, int(score / 33))\n",
    "\n",
    "        return exercise_focuses[score_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfa6c3c-a45f-4adc-963f-ef4bdbdddac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupes dÃ©tectÃ©s : {'core training': 0, 'hip dominant': 1, 'horizontal pulls': 2, 'horizontal pushes': 3, 'quad dominant': 4, 'vertical pulls': 5, 'vertical pushes': 6}\n",
      "Exercices dÃ©tectÃ©s : {'t bar row': 0, 'pull up': 1, 'hammer curl': 2, 'decline bench press': 3, 'tricep pushdown': 4, 'chest fly machine': 5, 'squat': 6, 'bench press': 7, 'push-up': 8, 'deadlift': 9, 'leg raises': 10, 'russian twist': 11, 'barbell biceps curl': 12, 'lateral raise': 13, 'hip thrust': 14, 'lat pulldown': 15, 'plank': 16, 'incline bench press': 17, 'tricep dips': 18, 'leg extension': 19, 'romanian deadlift': 20, 'shoulder press': 21}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EnhancedExerciseHierarchicalDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 exercices_points: dict,\n",
    "                 grouped_sports: dict,\n",
    "                 max_seq_len: int = 45,\n",
    "                 augment: bool = False,\n",
    "                 validate_physics: bool = True,\n",
    "                 data_dir: str = None):\n",
    "        \"\"\"\n",
    "        Dataset flexible pour exercices Posture â€“ supports preprocessed files or webcam-only mode.\n",
    "        \"\"\"\n",
    "        self.exercises_points  = exercices_points\n",
    "        self.grouped_sports    = grouped_sports\n",
    "        self.max_seq_len       = max_seq_len\n",
    "        self.augment           = augment\n",
    "        self.validate_physics  = validate_physics\n",
    "        self.data_dir          = data_dir\n",
    "\n",
    "        if self.data_dir:\n",
    "            # Mode prÃ©traitÃ© : scan des fichiers et chargement des samples\n",
    "            self._build_mappings_dynamic()\n",
    "            self.max_feature_dim = self._calculate_max_feature_dim(self.present_exercises)\n",
    "            self._load_samples_enhanced()\n",
    "            if self.validate_physics:\n",
    "                self._validate_dataset_quality()\n",
    "        else:\n",
    "            # Mode webcam only : initialisation directe des mappings\n",
    "            self.present_exercises = list(self.exercises_points.keys())\n",
    "            self.exercise_to_idx   = {ex: i for i, ex in enumerate(self.present_exercises)}\n",
    "            self.idx_to_exercise   = {i: ex for ex, i in self.exercise_to_idx.items()}\n",
    "            self.exercise_to_group = {\n",
    "                ex: grp\n",
    "                for grp, exercises in self.grouped_sports.items()\n",
    "                for ex in exercises\n",
    "                if ex in self.exercise_to_idx\n",
    "            }\n",
    "            present_groups = sorted(set(self.exercise_to_group.values()))\n",
    "            self.group_to_idx = {g: i for i, g in enumerate(present_groups)}\n",
    "            self.idx_to_group = {i: g for g, i in self.group_to_idx.items()}\n",
    "            self.max_feature_dim = self._calculate_max_feature_dim(self.present_exercises)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(getattr(self, 'samples', []))\n",
    "\n",
    "    def _build_mappings_dynamic(self):\n",
    "        \"\"\"Scan du rÃ©pertoire data_dir pour gÃ©nÃ©rer mappings et liste de samples.\"\"\"\n",
    "        self.present_exercises = []\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            self.exercise_to_idx = {}\n",
    "            self.idx_to_exercise = {}\n",
    "            self.exercise_to_group = {}\n",
    "            self.group_to_idx = {}\n",
    "            self.idx_to_group = {}\n",
    "            return\n",
    "\n",
    "        # RepÃ©rage des exercices valides\n",
    "        for ex in self.exercises_points:\n",
    "            ex_dir = os.path.join(self.data_dir, ex)\n",
    "            if os.path.isdir(ex_dir) and any(f.endswith('.npy') for f in os.listdir(ex_dir)):\n",
    "                if any(ex in lst for lst in self.grouped_sports.values()):\n",
    "                    self.present_exercises.append(ex)\n",
    "        self.present_exercises.sort()\n",
    "\n",
    "        # Mappings indices â†” exercices\n",
    "        self.exercise_to_idx = {ex: i for i, ex in enumerate(self.present_exercises)}\n",
    "        self.idx_to_exercise = {i: ex for ex, i in self.exercise_to_idx.items()}\n",
    "\n",
    "        # Mapping exercice â†’ groupe\n",
    "        self.exercise_to_group = {\n",
    "            ex: grp\n",
    "            for grp, exercises in self.grouped_sports.items()\n",
    "            for ex in exercises\n",
    "            if ex in self.exercise_to_idx\n",
    "        }\n",
    "\n",
    "        # Mappings indices â†” groupes\n",
    "        present_groups = sorted(set(self.exercise_to_group.values()))\n",
    "        self.group_to_idx = {g: i for i, g in enumerate(present_groups)}\n",
    "        self.idx_to_group = {i: g for g, i in self.group_to_idx.items()}\n",
    "\n",
    "    def _calculate_max_feature_dim(self, exercises: list) -> int:\n",
    "        \"\"\"Calcule la dimension maximale de features selon exercises_points.\"\"\"\n",
    "        max_dim = 0\n",
    "        for ex in exercises:\n",
    "            num_pts = len(self.exercises_points.get(ex, []))\n",
    "            # 3 coordonnÃ©es + angles (3) + distances (2) + dynamiques (2Ã—3Ã—num_pts)\n",
    "            dim = num_pts*3 + 3 + 2 + num_pts*3*2\n",
    "            max_dim = max(max_dim, dim)\n",
    "        return max_dim\n",
    "\n",
    "    def _load_samples_enhanced(self):\n",
    "        \"\"\"Charge les chemins de fichiers .npy, labels et groupes pour lâ€™entraÃ®nement.\"\"\"\n",
    "        self.samples, self.labels, self.groups, self.exercise_names = [], [], [], []\n",
    "        for ex in self.present_exercises:\n",
    "            ex_dir = os.path.join(self.data_dir, ex)\n",
    "            for fname in os.listdir(ex_dir):\n",
    "                if not fname.endswith('.npy'): continue\n",
    "                path = os.path.join(ex_dir, fname)\n",
    "                if os.path.getsize(path) < 100: continue  # Fichiers trop petits\n",
    "                self.samples.append(path)\n",
    "                self.labels.append(self.exercise_to_idx[ex])\n",
    "                self.groups.append(self.group_to_idx[self.exercise_to_group[ex]])\n",
    "                self.exercise_names.append(ex)\n",
    "\n",
    "    def _validate_dataset_quality(self):\n",
    "        \"\"\"Filtre les samples contenant NaN/Inf ou features statiques excessives.\"\"\"\n",
    "        valid_samples, valid_labels, valid_groups, valid_names = [], [], [], []\n",
    "        for s, l, g, n in zip(self.samples, self.labels, self.groups, self.exercise_names):\n",
    "            arr = np.load(s, mmap_mode='r')\n",
    "            if np.isnan(arr).any() or np.isinf(arr).any(): continue\n",
    "            var = np.var(arr, axis=0)\n",
    "            if (var < 1e-6).sum()/arr.shape[1] > 0.3: continue\n",
    "            valid_samples.append(s); valid_labels.append(l)\n",
    "            valid_groups.append(g); valid_names.append(n)\n",
    "        self.samples, self.labels = valid_samples, valid_labels\n",
    "        self.groups, self.exercise_names = valid_groups, valid_names\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        seq = np.load(path).astype(np.float32)\n",
    "        if np.isnan(seq).any() or np.isinf(seq).any():\n",
    "            return None\n",
    "        seq = torch.from_numpy(seq)\n",
    "        # Standardisation temporelle et dimensionnelle\n",
    "        seq = self._standardize_sequence(seq)\n",
    "        if self.augment: seq = self.augment_sequence(seq)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        group = torch.tensor(self.groups[idx], dtype=torch.long)\n",
    "        return seq, label, group\n",
    "\n",
    "    def _standardize_sequence(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Pad/trim features et sÃ©quences pour obtenir (max_seq_len Ã— max_feature_dim).\"\"\"\n",
    "        # Dimension features\n",
    "        d = seq.shape[1]\n",
    "        if d < self.max_feature_dim:\n",
    "            pad = self.max_feature_dim - d\n",
    "            seq = torch.nn.functional.pad(seq, (0, pad))\n",
    "        elif d > self.max_feature_dim:\n",
    "            seq = seq[:, :self.max_feature_dim]\n",
    "        # Temporal\n",
    "        t = seq.shape[0]\n",
    "        if t < self.max_seq_len:\n",
    "            seq = torch.nn.functional.pad(seq, (0, 0, 0, self.max_seq_len - t))\n",
    "        else:\n",
    "            seq = seq[:self.max_seq_len]\n",
    "        return seq\n",
    "\n",
    "    def augment_sequence(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Applique jitter, scaling, masking, permutation temporelle.\"\"\"\n",
    "        if random.random() < 0.5:\n",
    "            seq += torch.randn_like(seq) * (0.02 * torch.std(seq))\n",
    "        if random.random() < 0.5:\n",
    "            seq *= random.uniform(0.95, 1.05)\n",
    "        if random.random() < 0.3:\n",
    "            mask = (torch.rand_like(seq) > 0.15).float()\n",
    "            seq = seq * mask + (1-mask)*seq.mean()\n",
    "        if random.random() < 0.2 and seq.size(0) > 5:\n",
    "            splits = sorted(random.sample(range(1, seq.size(0)), random.randint(1,3)))\n",
    "            sizes = [splits[0]] + [splits[i+1]-splits[i] for i in range(len(splits)-1)] + [seq.size(0)-splits[-1]]\n",
    "            segments = torch.split(seq, sizes)\n",
    "            perm = torch.randperm(len(segments))\n",
    "            seq = torch.cat([segments[i] for i in perm], dim=0)[:self.max_seq_len]\n",
    "        return seq\n",
    "import json\n",
    "# Chargement des mappings depuis le JSON gÃ©nÃ©rÃ© avec le modÃ¨le\n",
    "with open(\"model_mappings.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "exercise_points = mappings[\"exercise_points\"]\n",
    "group_mapping  = mappings[\"group_mapping\"]\n",
    "\n",
    "# Instanciation sans dossier prÃ©traitÃ© (mode webcam uniquement)\n",
    "dataset = EnhancedExerciseHierarchicalDataset(\n",
    "    exercices_points=exercise_points,\n",
    "    grouped_sports=group_mapping,\n",
    "    max_seq_len=50,\n",
    "    augment=False,\n",
    "    validate_physics=True,\n",
    "    data_dir=None\n",
    ")\n",
    "\n",
    "print(\"Groupes dÃ©tectÃ©s :\", dataset.group_to_idx)          # Affiche les groupes [3]\n",
    "print(\"Exercices dÃ©tectÃ©s :\", dataset.exercise_to_idx)    # Affiche les exercices [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37c4081-ed7f-4c41-8fdf-7bcde2a08bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\OneDrive\\Bureau\\project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9748\\613325973.py:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import torch\n",
    "import json\n",
    "\n",
    "\n",
    "class PoseClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_groups, num_exercises):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                           bidirectional=True,\n",
    "                           num_layers=2,\n",
    "                           dropout=0.3)\n",
    "\n",
    "        # Attention Temporelle\n",
    "        self.attention = nn.MultiheadAttention(2*hidden_dim, 4)\n",
    "\n",
    "        # Branches Spécialisées\n",
    "        self.group_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_groups)\n",
    "        )\n",
    "\n",
    "        self.exercise_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_exercises)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # [batch, seq, 2*hidden]\n",
    "        out = out.permute(1, 0, 2)  # [seq, batch, 2*hidden]\n",
    "\n",
    "        # Mécanisme d'Attention\n",
    "        attn_out, _ = self.attention(out, out, out)\n",
    "        pooled = torch.mean(attn_out, dim=0)  # [batch, 2*hidden]\n",
    "\n",
    "        group = self.group_net(pooled)\n",
    "        exercise = self.exercise_net(pooled)\n",
    "\n",
    "        return group, exercise\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Charge un modèle PyTorch entraîné et ses mappings JSON,\n",
    "    puis fournit une méthode `predict` pour déduire le groupe et l’exercice.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, mappings_path, device='cpu'):\n",
    "        self.device = device\n",
    "        # Lecture des mappings JSON (idx_to_group, idx_to_exercise, dims)\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "        # Instanciation du modèle avec les dimensions sauvegardées\n",
    "        self.model = PoseClassificationModel(\n",
    "            input_dim   = self.mappings['input_dim'],\n",
    "            hidden_dim  = self.mappings['hidden_dim'],\n",
    "            num_groups      = self.mappings['num_groups'],\n",
    "            num_exercises   = self.mappings['num_exercises']\n",
    "        ).to(self.device)\n",
    "        # Chargement du checkpoint PyTorch\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, sequence_tensor):\n",
    "        \"\"\"\n",
    "        Prédit le groupe, l’exercice et la confiance pour une séquence de features.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            grp_out, ex_out = self.model(sequence_tensor)\n",
    "        grp_idx = grp_out.argmax(dim=1).item()\n",
    "        ex_idx  = ex_out.argmax(dim=1).item()\n",
    "        confidence = float(torch.softmax(ex_out, dim=1).max())\n",
    "        group    = self.mappings['idx_to_group'][str(grp_idx)]\n",
    "        exercise = self.mappings['idx_to_exercise'][str(ex_idx)]\n",
    "        return group, exercise, confidence\n",
    "\n",
    "    def _load_model_and_mappings(self, model_path, mappings_path):\n",
    "        \"\"\"Charge le meilleur modèle sauvegardé et ses mappings\"\"\"\n",
    "        # Charger les mappings\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "\n",
    "    def _calculate_biomech_metrics(self, sequences):\n",
    "        \"\"\"Calcule les métriques biomécaniques pour une séquence\"\"\"\n",
    "        # Simulation des métriques - à remplacer par votre logique réelle\n",
    "        return {\n",
    "            'angle_accuracy': np.random.uniform(0.7, 0.95),\n",
    "            'movement_quality': np.random.uniform(0.6, 0.9),\n",
    "            'stability_score': np.random.uniform(0.5, 0.85)\n",
    "        }\n",
    "\n",
    "    def generate_evaluation_report(self, results):\n",
    "        \"\"\"Génère un rapport détaillé d'évaluation\"\"\"\n",
    "        total_samples = sum(len(class_results) for class_results in results.values())\n",
    "        total_exercise_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['exercise_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "        total_group_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['group_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📈 RAPPORT d'ÉVALUATION GLOBAL\")\n",
    "        print(f\"=\" * 50)\n",
    "        print(f\"Échantillons analysés: {total_samples}\")\n",
    "        print(f\"Précision exercices: {total_exercise_correct/total_samples:.2%}\")\n",
    "        print(f\"Précision groupes: {total_group_correct/total_samples:.2%}\")\n",
    "\n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'exercise_accuracy': total_exercise_correct/total_samples,\n",
    "            'group_accuracy': total_group_correct/total_samples,\n",
    "            'detailed_results': results\n",
    "        }\n",
    "CHECKPOINT_PATH = \"pose_classification_model_best.pth\"\n",
    "MAPPINGS_PATH = \"model_mappings.json\"\n",
    "\n",
    "with open(\"model_mappings.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "\n",
    "class WebcamCorrector:\n",
    "    def __init__(self, evaluator, user_level='intermediate'):\n",
    "        self.evaluator = evaluator\n",
    "        self.user_level = user_level\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.drawing = mp.solutions.drawing_utils\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.tts.setProperty('rate', 150)\n",
    "        self.tts.setProperty('volume', 0.8)\n",
    "        self.sequence, self.max_len = [], 30\n",
    "        self.current_ex = None\n",
    "        self.max_feature_dim = evaluator.mappings['input_dim'] # Get expected input dimension from model mappings\n",
    "        self.standards = AdaptiveExerciseStandards() # Initialize AdaptiveExerciseStandards\n",
    "\n",
    "    def _extract_features(self, lm):\n",
    "        coords = [coord for p in lm.landmark for coord in (p.x, p.y, p.z)]\n",
    "        angles = self._compute_angles(lm)\n",
    "        dists  = self._compute_distances(lm)\n",
    "        features = np.array(coords + angles + dists, dtype=np.float32)\n",
    "\n",
    "        # Pad features to match the expected input dimension of the model\n",
    "        if features.shape[0] < self.max_feature_dim:\n",
    "            padding = self.max_feature_dim - features.shape[0]\n",
    "            features = np.pad(features, (0, padding), 'constant', constant_values=0)\n",
    "        elif features.shape[0] > self.max_feature_dim:\n",
    "            features = features[:self.max_feature_dim]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def _process_frame(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = self.pose.process(rgb)\n",
    "        corrs = []\n",
    "        if res.pose_landmarks:\n",
    "            self.drawing.draw_landmarks(frame, res.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n",
    "            features = self._extract_features(res.pose_landmarks)\n",
    "            self.sequence.append(features)\n",
    "            if len(self.sequence) > self.max_len:\n",
    "                self.sequence.pop(0)\n",
    "            if len(self.sequence) >= 15:\n",
    "                seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n",
    "                grp, ex, conf = self.evaluator.predict(seq_tensor)\n",
    "                # Generate corrections based on the predicted exercise and current user level\n",
    "                corrs = self._generate_corrections(ex, self.user_level)\n",
    "                return ex, grp, conf, corrs\n",
    "        return None, None, 0.0, corrs\n",
    "\n",
    "    def _compute_angles(self, lm):\n",
    "        def angle(a, b, c):\n",
    "            v1, v2 = a - b, c - b\n",
    "            cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
    "        idxs = [(12,14,16), (11,13,15), (24,26,28), (23,25,27)]  # 4 angles\n",
    "        pts = lm.landmark\n",
    "        return [angle(np.array([pts[i].x, pts[i].y]),\n",
    "                      np.array([pts[j].x, pts[j].y]),\n",
    "                      np.array([pts[k].x, pts[k].y]))\n",
    "                for i,j,k in idxs]\n",
    "\n",
    "    def _compute_distances(self, lm):\n",
    "        pts = lm.landmark\n",
    "        sl, sr = np.array([pts[11].x, pts[11].y]), np.array([pts[12].x, pts[12].y])\n",
    "        hl, hr = np.array([pts[23].x, pts[23].y]), np.array([pts[24].x, pts[24].y])\n",
    "        nose, hipc = np.array([pts[0].x, pts[0].y]), (hl + hr) / 2\n",
    "        return [np.linalg.norm(sr - sl),\n",
    "                np.linalg.norm(hr - hl),\n",
    "                np.linalg.norm(nose - hipc)]\n",
    "\n",
    "    def _generate_corrections(self, exercise, user_level):\n",
    "        \"\"\"Generate corrections based on exercise and user level.\"\"\"\n",
    "        # This is a placeholder. In a real application, you would analyze the\n",
    "        # biomechanical data (angles, distances, etc.) from the 'features'\n",
    "        # variable to determine specific errors and generate corrections\n",
    "        # using the AdaptiveExerciseStandards class.\n",
    "        # For now, we'll just return some generic corrections for demonstration.\n",
    "        if exercise in self.standards.exercise_standards:\n",
    "            # Simulate detecting some common errors based on user level\n",
    "            errors = []\n",
    "            if user_level == 'novice':\n",
    "                errors = ['back_not_straight', 'not_low_enough'] # Example novice errors\n",
    "            elif user_level == 'intermediate':\n",
    "                 errors = ['arms_too_wide', 'body_not_straight'] # Example intermediate errors\n",
    "            elif user_level == 'expert':\n",
    "                 errors = ['back_not_straight'] # Example expert errors\n",
    "\n",
    "            corrections = []\n",
    "            for error_type in errors:\n",
    "                 correction_message = self.standards.get_adaptive_correction(exercise, error_type, user_level)\n",
    "                 corrections.append({'message': correction_message, 'severity': 'medium'}) # Simulate medium severity\n",
    "\n",
    "            if not corrections and exercise in ['squat', 'push-up', 'deadlift']:\n",
    "                 # Add a progression tip if no specific errors are detected for these exercises\n",
    "                 progression_tip = self.standards.get_adaptive_correction(exercise, 'progression_tip', user_level)\n",
    "                 if progression_tip:\n",
    "                     corrections.append({'message': progression_tip, 'severity': 'low'})\n",
    "\n",
    "            return corrections\n",
    "\n",
    "        return []\n",
    "\n",
    "    def _draw(self, frame, corrs):\n",
    "        \"\"\"Superpose l’overlay, le niveau utilisateur et les corrections.\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5,5), (w-5,140), (0,0,0), -1)\n",
    "        frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)\n",
    "        y = 30\n",
    "        cv2.putText(frame, f\"Niveau: {self.user_level}\", (10,y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        for c in corrs[:3]:\n",
    "            y += 25\n",
    "            color = (0,0,255) if c.get('severity','low')=='high' else (0,165,255)\n",
    "            cv2.putText(frame, c['message'], (10,y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        return frame\n",
    "\n",
    "    def _speak(self, text):\n",
    "        \"\"\"Synthétise et prononce un texte.\"\"\"\n",
    "        try:\n",
    "            self.tts.say(text)\n",
    "            self.tts.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during text-to-speech: {e}\")\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        # Variables pour estimation de niveau\n",
    "        confidence_buffer = []\n",
    "        WINDOW_SIZE = 30\n",
    "        last_spoken_exercise = None\n",
    "        last_spoken_correction = None\n",
    "\n",
    "        # Démarrage de la capture vidéo\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Impossible d'ouvrir la webcam\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Prédiction et corrections\n",
    "            ex, grp, conf, corrs = self._process_frame(frame)\n",
    "            if ex:\n",
    "                # Mise à jour du buffer de confiance\n",
    "                confidence_buffer.append(conf)\n",
    "                if len(confidence_buffer) > WINDOW_SIZE:\n",
    "                    confidence_buffer.pop(0)\n",
    "                avg_conf = np.mean(confidence_buffer)\n",
    "\n",
    "                # Estimation simple du niveau\n",
    "                if avg_conf >= 0.85:\n",
    "                    level = \"expert\"\n",
    "                elif avg_conf >= 0.70:\n",
    "                    level = \"intermediate\"\n",
    "                else:\n",
    "                    level = \"novice\"\n",
    "\n",
    "                # Update user level in the corrector instance\n",
    "                self.user_level = level\n",
    "\n",
    "                # Affichage des informations\n",
    "                cv2.putText(frame, f\"Groupe: {grp}\", (10,30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                cv2.putText(frame, f\"Exercice: {ex}\", (10,60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                cv2.putText(frame, f\"Niveau estimé: {level}\", (10,90),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "                # Annonce vocale de l'exercice et des corrections\n",
    "                if ex != last_spoken_exercise:\n",
    "                    self._speak(f\"Exercice détecté : {ex}\")\n",
    "                    last_spoken_exercise = ex\n",
    "                    last_spoken_correction = None # Reset correction spoken when exercise changes\n",
    "\n",
    "                if corrs and corrs[0]['message'] != last_spoken_correction:\n",
    "                     self._speak(corrs[0]['message']) # Speak the first correction\n",
    "                     last_spoken_correction = corrs[0]['message']\n",
    "\n",
    "\n",
    "            # Dessin des corrections et affichage\n",
    "            annotated = self._draw(frame, corrs)\n",
    "            cv2.imshow('Analyse Niveau', annotated)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "exercise_points = mappings[\"exercise_points\"]\n",
    "group_mapping  = mappings[\"group_mapping\"]\n",
    "# Initialisation de l’évaluateur de modèle\n",
    "evaluator = ModelEvaluator(\n",
    "    model_path=CHECKPOINT_PATH,\n",
    "    mappings_path=MAPPINGS_PATH,\n",
    "    device='cpu'\n",
    ")                                                                                    # [3]\n",
    "\n",
    "\n",
    "# Instanciation du correcteur webcam\n",
    "wc = WebcamCorrector(evaluator=evaluator, user_level='novice')\n",
    "\n",
    "# 3. Démarrer la boucle\n",
    "wc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e4aed-dcf5-4d65-b7a2-101268299bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import torch\n",
    "import json\n",
    "import speech_recognition as sr # Import the speech_recognition library\n",
    "\n",
    "\n",
    "class PoseClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_groups, num_exercises):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                           bidirectional=True,\n",
    "                           num_layers=2,\n",
    "                           dropout=0.3)\n",
    "\n",
    "        # Attention Temporelle\n",
    "        self.attention = nn.MultiheadAttention(2*hidden_dim, 4)\n",
    "\n",
    "        # Branches Spécialisées\n",
    "        self.group_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_groups)\n",
    "        )\n",
    "\n",
    "        self.exercise_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_exercises)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # [batch, seq, 2*hidden]\n",
    "        out = out.permute(1, 0, 2)  # [seq, batch, 2*hidden]\n",
    "\n",
    "        # Mécanisme d'Attention\n",
    "        attn_out, _ = self.attention(out, out, out)\n",
    "        pooled = torch.mean(attn_out, dim=0)  # [batch, 2*hidden]\n",
    "\n",
    "        group = self.group_net(pooled)\n",
    "        exercise = self.exercise_net(pooled)\n",
    "\n",
    "        return group, exercise\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Charge un modèle PyTorch entraîné et ses mappings JSON,\n",
    "    puis fournit une méthode `predict` pour déduire le groupe et l’exercice.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, mappings_path, device='cpu'):\n",
    "        self.device = device\n",
    "        # Lecture des mappings JSON (idx_to_group, idx_to_exercise, dims)\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "        # Instanciation du modèle avec les dimensions sauvegardées\n",
    "        self.model = PoseClassificationModel(\n",
    "            input_dim   = self.mappings['input_dim'],\n",
    "            hidden_dim  = self.mappings['hidden_dim'],\n",
    "            num_groups      = self.mappings['num_groups'],\n",
    "            num_exercises   = self.mappings['num_exercises']\n",
    "        ).to(self.device)\n",
    "        # Chargement du checkpoint PyTorch\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, sequence_tensor):\n",
    "        \"\"\"\n",
    "        Prédit le groupe, l’exercice et la confiance pour une séquence de features.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            grp_out, ex_out = self.model(sequence_tensor)\n",
    "        grp_idx = grp_out.argmax(dim=1).item()\n",
    "        ex_idx  = ex_out.argmax(dim=1).item()\n",
    "        confidence = float(torch.softmax(ex_out, dim=1).max())\n",
    "        group    = self.mappings['idx_to_group'][str(grp_idx)]\n",
    "        exercise = self.mappings['idx_to_exercise'][str(ex_idx)]\n",
    "        return group, exercise, confidence\n",
    "\n",
    "    def _load_model_and_mappings(self, model_path, mappings_path):\n",
    "        \"\"\"Charge le meilleur modèle sauvegardé et ses mappings\"\"\"\n",
    "        # Charger les mappings\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "\n",
    "    def _calculate_biomech_metrics(self, sequences):\n",
    "        \"\"\"Calcule les métriques biomécaniques pour une séquence\"\"\"\n",
    "        # Simulation des métriques - à remplacer par votre logique réelle\n",
    "        return {\n",
    "            'angle_accuracy': np.random.uniform(0.7, 0.95),\n",
    "            'movement_quality': np.random.uniform(0.6, 0.9),\n",
    "            'stability_score': np.random.uniform(0.5, 0.85)\n",
    "        }\n",
    "\n",
    "    def generate_evaluation_report(self, results):\n",
    "        \"\"\"Génère un rapport détaillé d'évaluation\"\"\"\n",
    "        total_samples = sum(len(class_results) for class_results in results.values())\n",
    "        total_exercise_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['exercise_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "        total_group_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['group_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📈 RAPPORT d'ÉVALUATION GLOBAL\")\n",
    "        print(f\"=\" * 50)\n",
    "        print(f\"Échantillons analysés: {total_samples}\")\n",
    "        print(f\"Précision exercices: {total_exercise_correct/total_samples:.2%}\")\n",
    "        print(f\"Précision groupes: {total_group_correct/total_samples:.2%}\")\n",
    "\n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'exercise_accuracy': total_exercise_correct/total_samples,\n",
    "            'group_accuracy': total_group_correct/total_samples,\n",
    "            'detailed_results': results\n",
    "        }\n",
    "CHECKPOINT_PATH = \"pose_classification_model_best.pth\"\n",
    "MAPPINGS_PATH = \"model_mappings.json\"\n",
    "\n",
    "with open(\"model_mappings.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "\n",
    "class WebcamCorrector:\n",
    "    def __init__(self, evaluator, user_level='intermediate'):\n",
    "        self.evaluator = evaluator\n",
    "        self.user_level = user_level\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.drawing = mp.solutions.drawing_utils\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.tts.setProperty('rate', 150)\n",
    "        self.tts.setProperty('volume', 0.8)\n",
    "        self.sequence, self.max_len = [], 30\n",
    "        self.current_ex = None\n",
    "        self.max_feature_dim = evaluator.mappings['input_dim'] # Get expected input dimension from model mappings\n",
    "        self.standards = AdaptiveExerciseStandards() # Initialize AdaptiveExerciseStandards\n",
    "        self.recognizer = sr.Recognizer() # Initialize speech recognizer\n",
    "\n",
    "\n",
    "    def _extract_features(self, lm):\n",
    "        coords = [coord for p in lm.landmark for coord in (p.x, p.y, p.z)]\n",
    "        angles = self._compute_angles(lm)\n",
    "        dists  = self._compute_distances(lm)\n",
    "        features = np.array(coords + angles + dists, dtype=np.float32)\n",
    "\n",
    "        # Pad features to match the expected input dimension of the model\n",
    "        if features.shape[0] < self.max_feature_dim:\n",
    "            padding = self.max_feature_dim - features.shape[0]\n",
    "            features = np.pad(features, (0, padding), 'constant', constant_values=0)\n",
    "        elif features.shape[0] > self.max_feature_dim:\n",
    "            features = features[:self.max_feature_dim]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def _process_frame(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = self.pose.process(rgb)\n",
    "        corrs = []\n",
    "        if res.pose_landmarks:\n",
    "            self.drawing.draw_landmarks(frame, res.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n",
    "            features = self._extract_features(res.pose_landmarks)\n",
    "            self.sequence.append(features)\n",
    "            if len(self.sequence) > self.max_len:\n",
    "                self.sequence.pop(0)\n",
    "            if len(self.sequence) >= 15:\n",
    "                seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n",
    "                grp, ex, conf = self.evaluator.predict(seq_tensor)\n",
    "                # Generate corrections based on the predicted exercise and current user level\n",
    "                corrs = self._generate_corrections(ex, self.user_level)\n",
    "                return ex, grp, conf, corrs\n",
    "        return None, None, 0.0, corrs\n",
    "\n",
    "    def _compute_angles(self, lm):\n",
    "        def angle(a, b, c):\n",
    "            v1, v2 = a - b, c - b\n",
    "            cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
    "        idxs = [(12,14,16), (11,13,15), (24,26,28), (23,25,27)]  # 4 angles\n",
    "        pts = lm.landmark\n",
    "        return [angle(np.array([pts[i].x, pts[i].y]),\n",
    "                      np.array([pts[j].x, pts[j].y]),\n",
    "                      np.array([pts[k].x, pts[k].y]))\n",
    "                for i,j,k in idxs]\n",
    "\n",
    "    def _compute_distances(self, lm):\n",
    "        pts = lm.landmark\n",
    "        sl, sr = np.array([pts[11].x, pts[11].y]), np.array([pts[12].x, pts[12].y])\n",
    "        hl, hr = np.array([pts[23].x, pts[23].y]), np.array([pts[24].x, pts[24].y])\n",
    "        nose, hipc = np.array([pts[0].x, pts[0].y]), (hl + hr) / 2\n",
    "        return [np.linalg.norm(sr - sl),\n",
    "                np.linalg.norm(hr - hl),\n",
    "                np.linalg.norm(nose - hipc)]\n",
    "\n",
    "    def _generate_corrections(self, exercise, user_level):\n",
    "        \"\"\"Generate corrections based on exercise and user level.\"\"\"\n",
    "        # This is a placeholder. In a real application, you would analyze the\n",
    "        # biomechanical data (angles, distances, etc.) from the 'features'\n",
    "        # variable to determine specific errors and generate corrections\n",
    "        # using the AdaptiveExerciseStandards class.\n",
    "        # For now, we'll just return some generic corrections for demonstration.\n",
    "        if exercise in self.standards.exercise_standards:\n",
    "            # Simulate detecting some common errors based on user level\n",
    "            errors = []\n",
    "            if user_level == 'novice':\n",
    "                errors = ['back_not_straight', 'not_low_enough'] # Example novice errors\n",
    "            elif user_level == 'intermediate':\n",
    "                 errors = ['arms_too_wide', 'body_not_straight'] # Example intermediate errors\n",
    "            elif user_level == 'expert':\n",
    "                 errors = ['back_not_straight'] # Example expert errors\n",
    "\n",
    "            corrections = []\n",
    "            for error_type in errors:\n",
    "                 correction_message = self.standards.get_adaptive_correction(exercise, error_type, user_level)\n",
    "                 corrections.append({'message': correction_message, 'severity': 'medium'}) # Simulate medium severity\n",
    "\n",
    "            if not corrections and exercise in ['squat', 'push-up', 'deadlift']:\n",
    "                 # Add a progression tip if no specific errors are detected for these exercises\n",
    "                 progression_tip = self.standards.get_adaptive_correction(exercise, 'progression_tip', user_level)\n",
    "                 if progression_tip:\n",
    "                     corrections.append({'message': progression_tip, 'severity': 'low'})\n",
    "\n",
    "            return corrections\n",
    "\n",
    "        return []\n",
    "\n",
    "    def _draw(self, frame, corrs):\n",
    "        \"\"\"Superpose l’overlay, le niveau utilisateur et les corrections.\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5,5), (w-5,140), (0,0,0), -1)\n",
    "        frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)\n",
    "        y = 30\n",
    "        cv2.putText(frame, f\"Niveau: {self.user_level}\", (10,y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        for c in corrs[:3]:\n",
    "            y += 25\n",
    "            color = (0,0,255) if c.get('severity','low')=='high' else (0,165,255)\n",
    "            cv2.putText(frame, c['message'], (10,y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        return frame\n",
    "\n",
    "    def _speak(self, text):\n",
    "        \"\"\"Synthétise et prononce un texte.\"\"\"\n",
    "        try:\n",
    "            self.tts.say(text)\n",
    "            self.tts.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during text-to-speech: {e}\")\n",
    "\n",
    "    def _listen_command(self):\n",
    "        \"\"\"Listens for a voice command from the microphone and transcribes it.\"\"\"\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something!\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1) # Adjust for noise\n",
    "            audio = self.recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = self.recognizer.recognize_google(audio, language=\"en-US\") # You can change the language if needed\n",
    "            print(f\"You said: {command}\")\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "            return None\n",
    "\n",
    "    def start(self):\n",
    "        # Variables pour estimation de niveau\n",
    "        confidence_buffer = []\n",
    "        WINDOW_SIZE = 30\n",
    "        last_spoken_exercise = None\n",
    "        last_spoken_correction = None\n",
    "        command_active = False # Flag to indicate if a voice command is active\n",
    "        command_exercise = None # Exercise specified by voice command\n",
    "        command_reps = 0 # Repetitions specified by voice command\n",
    "        current_reps = 0 # Counter for repetitions performed\n",
    "\n",
    "\n",
    "        # Démarrage de la capture vidéo\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Impossible d'ouvrir la webcam\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Listen for a voice command (can be triggered by a key press or at intervals)\n",
    "            # For now, let's listen when 'c' is pressed\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                command = self._listen_command()\n",
    "                if command:\n",
    "                    # Process the command (This will be refined in the next step)\n",
    "                    # Basic parsing for \"number exercise\" format\n",
    "                    parts = command.split()\n",
    "                    if len(parts) >= 2 and parts[0].isdigit():\n",
    "                        try:\n",
    "                            command_reps = int(parts[0])\n",
    "                            command_exercise = \" \".join(parts[1:]).lower()\n",
    "                            print(f\"Command received: {command_reps} {command_exercise}\")\n",
    "                            command_active = True\n",
    "                            current_reps = 0 # Reset rep counter for new command\n",
    "                            self._speak(f\"Okay, let's do {command_reps} {command_exercise}s.\")\n",
    "                        except ValueError:\n",
    "                            self._speak(\"Sorry, I didn't understand the number of repetitions.\")\n",
    "                    else:\n",
    "                        self._speak(\"Sorry, I didn't understand the command format. Please say 'number exercise'.\")\n",
    "\n",
    "\n",
    "            # Prédiction et corrections\n",
    "            ex, grp, conf, corrs = self._process_frame(frame)\n",
    "\n",
    "            # If a command is active, use the commanded exercise instead of the predicted one\n",
    "            if command_active and command_exercise:\n",
    "                 ex = command_exercise\n",
    "                 # Regenerate corrections based on the commanded exercise and current user level\n",
    "                 corrs = self._generate_corrections(ex, self.user_level)\n",
    "\n",
    "\n",
    "            if ex:\n",
    "                # Mise à jour du buffer de confiance\n",
    "                confidence_buffer.append(conf)\n",
    "                if len(confidence_buffer) > WINDOW_SIZE:\n",
    "                    confidence_buffer.pop(0)\n",
    "                avg_conf = np.mean(confidence_buffer)\n",
    "\n",
    "                # Estimation simple du niveau\n",
    "                if avg_conf >= 0.85:\n",
    "                    level = \"expert\"\n",
    "                elif avg_conf >= 0.70:\n",
    "                    level = \"intermediate\"\n",
    "                else:\n",
    "                    level = \"novice\"\n",
    "\n",
    "                # Update user level in the corrector instance\n",
    "                self.user_level = level\n",
    "\n",
    "\n",
    "                # Affichage des informations\n",
    "                cv2.putText(frame, f\"Groupe: {grp}\", (10,30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                cv2.putText(frame, f\"Exercice: {ex}\", (10,60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                cv2.putText(frame, f\"Niveau estimé: {level}\", (10,90),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "                # Annonce vocale de l'exercice et des corrections\n",
    "                if ex != last_spoken_exercise:\n",
    "                    if not command_active: # Only announce detected exercise if no command is active\n",
    "                        self._speak(f\"Exercice détecté : {ex}\")\n",
    "                    last_spoken_exercise = ex\n",
    "                    last_spoken_correction = None # Reset correction spoken when exercise changes\n",
    "\n",
    "                if corrs and corrs[0]['message'] != last_spoken_correction:\n",
    "                    # Only speak corrections if a command is active or if no command is active and an exercise is detected\n",
    "                    if command_active or (not command_active and ex):\n",
    "                         self._speak(corrs[0]['message']) # Speak the first correction\n",
    "                         last_spoken_correction = corrs[0]['message']\n",
    "\n",
    "                # Repetition tracking (Placeholder - needs actual movement detection logic)\n",
    "                # This is where you would add logic to detect a completed repetition\n",
    "                # and increment current_reps. For now, we'll just demonstrate the display.\n",
    "                if command_active:\n",
    "                     cv2.putText(frame, f\"Reps: {current_reps}/{command_reps}\", (10,120),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "                     if current_reps >= command_reps and command_reps > 0:\n",
    "                          self._speak(f\"Great job! You completed {command_reps} {command_exercise}s.\")\n",
    "                          command_active = False # Deactivate command after completing reps\n",
    "                          command_exercise = None\n",
    "                          command_reps = 0\n",
    "\n",
    "\n",
    "            # Dessin des corrections et affichage\n",
    "            annotated = self._draw(frame, corrs)\n",
    "            cv2.imshow('Analyse Niveau', annotated)\n",
    "\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "exercise_points = mappings[\"exercise_points\"]\n",
    "group_mapping  = mappings[\"group_mapping\"]\n",
    "# Initialisation de l’évaluateur de modèle\n",
    "evaluator = ModelEvaluator(\n",
    "    model_path=CHECKPOINT_PATH,\n",
    "    mappings_path=MAPPINGS_PATH,\n",
    "    device='cpu'\n",
    ")                                                                                    # [3]\n",
    "\n",
    "\n",
    "# Instanciation du correcteur webcam\n",
    "wc = WebcamCorrector(evaluator=evaluator, user_level='novice')\n",
    "\n",
    "# 3. Démarrer la boucle\n",
    "wc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d8300f-5e75-4558-885b-d86529f11c74",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 479\u001b[0m\n\u001b[0;32m    476\u001b[0m wc \u001b[38;5;241m=\u001b[39m WebcamCorrector(evaluator\u001b[38;5;241m=\u001b[39mevaluator, user_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnovice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# 3. Démarrer la boucle\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m \u001b[43mwc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 360\u001b[0m, in \u001b[0;36mWebcamCorrector.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m last_spoken_correction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# command_active = False # Flag to indicate if a voice command is active - managed by current_command now\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# command_exercise = None # Exercise specified by voice command\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# command_reps = 0 # Repetitions specified by voice command\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# Démarrage de la capture vidéo\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouvrir la webcam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import torch\n",
    "import json\n",
    "import speech_recognition as sr # Import the speech_recognition library\n",
    "\n",
    "\n",
    "class PoseClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_groups, num_exercises):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                           bidirectional=True,\n",
    "                           num_layers=2,\n",
    "                           dropout=0.3)\n",
    "\n",
    "        # Attention Temporelle\n",
    "        self.attention = nn.MultiheadAttention(2*hidden_dim, 4)\n",
    "\n",
    "        # Branches Spécialisées\n",
    "        self.group_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_groups)\n",
    "        )\n",
    "\n",
    "        self.exercise_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_exercises)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # [batch, seq, 2*hidden]\n",
    "        out = out.permute(1, 0, 2)  # [seq, batch, 2*hidden]\n",
    "\n",
    "        # Mécanisme d'Attention\n",
    "        attn_out, _ = self.attention(out, out, out)\n",
    "        pooled = torch.mean(attn_out, dim=0)  # [batch, 2*hidden]\n",
    "\n",
    "        group = self.group_net(pooled)\n",
    "        exercise = self.exercise_net(pooled)\n",
    "\n",
    "        return group, exercise\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Charge un modèle PyTorch entraîné et ses mappings JSON,\n",
    "    puis fournit une méthode `predict` pour déduire le groupe et l’exercice.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, mappings_path, device='cpu'):\n",
    "        self.device = device\n",
    "        # Lecture des mappings JSON (idx_to_group, idx_to_exercise, dims)\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "        # Instanciation du modèle avec les dimensions sauvegardées\n",
    "        self.model = PoseClassificationModel(\n",
    "            input_dim   = self.mappings['input_dim'],\n",
    "            hidden_dim  = self.mappings['hidden_dim'],\n",
    "            num_groups      = self.mappings['num_groups'],\n",
    "            num_exercises   = self.mappings['num_exercises']\n",
    "        ).to(self.device)\n",
    "        # Chargement du checkpoint PyTorch\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, sequence_tensor):\n",
    "        \"\"\"\n",
    "        Prédit le groupe, l’exercice et la confiance pour une séquence de features.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            grp_out, ex_out = self.model(sequence_tensor)\n",
    "        grp_idx = grp_out.argmax(dim=1).item()\n",
    "        ex_idx  = ex_out.argmax(dim=1).item()\n",
    "        confidence = float(torch.softmax(ex_out, dim=1).max())\n",
    "        group    = self.mappings['idx_to_group'][str(grp_idx)]\n",
    "        exercise = self.mappings['idx_to_exercise'][str(ex_idx)]\n",
    "        return group, exercise, confidence\n",
    "\n",
    "    def _load_model_and_mappings(self, model_path, mappings_path):\n",
    "        \"\"\"Charge le meilleur modèle sauvegardé et ses mappings\"\"\"\n",
    "        # Charger les mappings\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "\n",
    "    def _calculate_biomech_metrics(self, sequences):\n",
    "        \"\"\"Calcule les métriques biomécaniques pour une séquence\"\"\"\n",
    "        # Simulation des métriques - à remplacer par votre logique réelle\n",
    "        return {\n",
    "            'angle_accuracy': np.random.uniform(0.7, 0.95),\n",
    "            'movement_quality': np.random.uniform(0.6, 0.9),\n",
    "            'stability_score': np.random.uniform(0.5, 0.85)\n",
    "        }\n",
    "\n",
    "    def generate_evaluation_report(self, results):\n",
    "        \"\"\"Génère un rapport détaillé d'évaluation\"\"\"\n",
    "        total_samples = sum(len(class_results) for class_results in results.values())\n",
    "        total_exercise_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['exercise_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "        total_group_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['group_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📈 RAPPORT d'ÉVALUATION GLOBAL\")\n",
    "        print(f\"=\" * 50)\n",
    "        print(f\"Échantillons analysés: {total_samples}\")\n",
    "        print(f\"Précision exercices: {total_exercise_correct/total_samples:.2%}\")\n",
    "        print(f\"Précision groupes: {total_group_correct/total_samples:.2%}\")\n",
    "\n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'exercise_accuracy': total_exercise_correct/total_samples,\n",
    "            'group_accuracy': total_group_correct/total_samples,\n",
    "            'detailed_results': results\n",
    "        }\n",
    "CHECKPOINT_PATH = \"pose_classification_model_best.pth\"\n",
    "MAPPINGS_PATH = \"model_mappings.json\"\n",
    "\n",
    "with open(\"model_mappings.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "\n",
    "class WebcamCorrector:\n",
    "    def __init__(self, evaluator, user_level='intermediate'):\n",
    "        self.evaluator = evaluator\n",
    "        self.user_level = user_level\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.drawing = mp.solutions.drawing_utils\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.tts.setProperty('rate', 150)\n",
    "        self.tts.setProperty('volume', 0.8)\n",
    "        self.sequence, self.max_len = [], 30\n",
    "        self.current_ex = None\n",
    "        self.max_feature_dim = evaluator.mappings['input_dim'] # Get expected input dimension from model mappings\n",
    "        self.standards = AdaptiveExerciseStandards() # Initialize AdaptiveExerciseStandards\n",
    "        self.recognizer = sr.Recognizer() # Initialize speech recognizer\n",
    "        self.command_queue = [] # To store list of (reps, exercise) tuples\n",
    "        self.current_command = None # To store the current (reps, exercise) tuple being guided\n",
    "        self.current_command_reps_completed = 0 # To track completed reps for the current command\n",
    "\n",
    "\n",
    "    def _extract_features(self, lm):\n",
    "        coords = [coord for p in lm.landmark for coord in (p.x, p.y, p.z)]\n",
    "        angles = self._compute_angles(lm)\n",
    "        dists  = self._compute_distances(lm)\n",
    "        features = np.array(coords + angles + dists, dtype=np.float32)\n",
    "\n",
    "        # Pad features to match the expected input dimension of the model\n",
    "        if features.shape[0] < self.max_feature_dim:\n",
    "            padding = self.max_feature_dim - features.shape[0]\n",
    "            features = np.pad(features, (0, padding), 'constant', constant_values=0)\n",
    "        elif features.shape[0] > self.max_feature_dim:\n",
    "            features = features[:self.max_feature_dim]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def _process_frame(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = self.pose.process(rgb)\n",
    "        corrs = []\n",
    "        predicted_ex = None # Store the predicted exercise separately\n",
    "\n",
    "        if res.pose_landmarks:\n",
    "            self.drawing.draw_landmarks(frame, res.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n",
    "            features = self._extract_features(res.pose_landmarks)\n",
    "            self.sequence.append(features)\n",
    "            if len(self.sequence) > self.max_len:\n",
    "                self.sequence.pop(0)\n",
    "\n",
    "            if len(self.sequence) >= 15:\n",
    "                seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n",
    "                grp, predicted_ex, conf = self.evaluator.predict(seq_tensor)\n",
    "\n",
    "                # If a command is active, use the commanded exercise for corrections\n",
    "                if self.current_command:\n",
    "                     commanded_reps, commanded_exercise = self.current_command\n",
    "                     corrs = self._generate_corrections(commanded_exercise, self.user_level)\n",
    "                     return commanded_exercise, grp, conf, corrs # Return commanded exercise\n",
    "\n",
    "                else:\n",
    "                    # Otherwise, use the predicted exercise for corrections\n",
    "                    corrs = self._generate_corrections(predicted_ex, self.user_level)\n",
    "                    return predicted_ex, grp, conf, corrs # Return predicted exercise\n",
    "\n",
    "        return None, None, 0.0, corrs # Return None for exercise if no landmarks\n",
    "\n",
    "\n",
    "    def _compute_angles(self, lm):\n",
    "        def angle(a, b, c):\n",
    "            v1, v2 = a - b, c - b\n",
    "            cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
    "        idxs = [(12,14,16), (11,13,15), (24,26,28), (23,25,27)]  # 4 angles\n",
    "        pts = lm.landmark\n",
    "        return [angle(np.array([pts[i].x, pts[i].y]),\n",
    "                      np.array([pts[j].x, pts[j].y]),\n",
    "                      np.array([pts[k].x, pts[k].y]))\n",
    "                for i,j,k in idxs]\n",
    "\n",
    "    def _compute_distances(self, lm):\n",
    "        pts = lm.landmark\n",
    "        sl, sr = np.array([pts[11].x, pts[11].y]), np.array([pts[12].x, pts[12].y])\n",
    "        hl, hr = np.array([pts[23].x, pts[23].y]), np.array([pts[24].x, pts[24].y])\n",
    "        nose, hipc = np.array([pts[0].x, pts[0].y]), (hl + hr) / 2\n",
    "        return [np.linalg.norm(sr - sl),\n",
    "                np.linalg.norm(hr - hl),\n",
    "                np.linalg.norm(nose - hipc)]\n",
    "\n",
    "    def _generate_corrections(self, exercise, user_level):\n",
    "        \"\"\"Generate corrections based on exercise and user level.\"\"\"\n",
    "        # This is a placeholder. In a real application, you would analyze the\n",
    "        # biomechanical data (angles, distances, etc.) from the 'features'\n",
    "        # variable to determine specific errors and generate corrections\n",
    "        # using the AdaptiveExerciseStandards class.\n",
    "        # For now, we'll just return some generic corrections for demonstration.\n",
    "        if exercise in self.standards.exercise_standards:\n",
    "            # Simulate detecting some common errors based on user level\n",
    "            errors = []\n",
    "            if user_level == 'novice':\n",
    "                errors = ['back_not_straight', 'not_low_enough'] # Example novice errors\n",
    "            elif user_level == 'intermediate':\n",
    "                 errors = ['arms_too_wide', 'body_not_straight'] # Example intermediate errors\n",
    "            elif user_level == 'expert':\n",
    "                 errors = ['back_not_straight'] # Example expert errors\n",
    "\n",
    "            corrections = []\n",
    "            for error_type in errors:\n",
    "                 correction_message = self.standards.get_adaptive_correction(exercise, error_type, user_level)\n",
    "                 corrections.append({'message': correction_message, 'severity': 'medium'}) # Simulate medium severity\n",
    "\n",
    "            if not corrections and exercise in ['squat', 'push-up', 'deadlift']:\n",
    "                 # Add a progression tip if no specific errors are detected for these exercises\n",
    "                 progression_tip = self.standards.get_adaptive_correction(exercise, 'progression_tip', user_level)\n",
    "                 if progression_tip:\n",
    "                     corrections.append({'message': progression_tip, 'severity': 'low'})\n",
    "\n",
    "            return corrections\n",
    "\n",
    "        return []\n",
    "\n",
    "    def _draw(self, frame, corrs):\n",
    "        \"\"\"Superpose l’overlay, le niveau utilisateur et les corrections.\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        overlay = frame.copy()\n",
    "        # Adjust overlay height to accommodate command info\n",
    "        cv2.rectangle(overlay, (5,5), (w-5,165), (0,0,0), -1)\n",
    "        frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)\n",
    "        y = 30\n",
    "        cv2.putText(frame, f\"Niveau: {self.user_level}\", (10,y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "        if self.current_command:\n",
    "            commanded_reps, commanded_exercise = self.current_command\n",
    "            cv2.putText(frame, f\"Commande: {commanded_reps} {commanded_exercise}\", (10, y + 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Reps: {self.current_command_reps_completed}/{commanded_reps}\", (10, y + 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            y += 60 # Adjust starting y for corrections\n",
    "\n",
    "        elif self.current_ex: # Display predicted exercise if no command is active\n",
    "             cv2.putText(frame, f\"Exercice: {self.current_ex}\", (10,y+30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "             cv2.putText(frame, f\"Groupe: {self.current_grp}\", (10,y+60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "             y += 60 # Adjust starting y for corrections\n",
    "\n",
    "\n",
    "        for c in corrs[:3]:\n",
    "            y += 25\n",
    "            color = (0,0,255) if c.get('severity','low')=='high' else (0,165,255)\n",
    "            cv2.putText(frame, c['message'], (10,y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        return frame\n",
    "\n",
    "    def _speak(self, text):\n",
    "        \"\"\"Synthétise et prononce un texte.\"\"\"\n",
    "        try:\n",
    "            self.tts.say(text)\n",
    "            self.tts.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during text-to-speech: {e}\")\n",
    "\n",
    "    def _listen_command(self):\n",
    "        \"\"\"Listens for a voice command from the microphone and transcribes it.\"\"\"\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something!\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1) # Adjust for noise\n",
    "            audio = self.recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = self.recognizer.recognize_google(audio, language=\"en-US\") # You can change the language if needed\n",
    "            print(f\"You said: {command}\")\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_command(self, command_string):\n",
    "        \"\"\"Parses a command string like '10 squat then 20 deadlift' into a list of (reps, exercise) tuples.\"\"\"\n",
    "        commands = []\n",
    "        parts = command_string.lower().split(\" then \")\n",
    "        for part in parts:\n",
    "            sub_parts = part.split()\n",
    "            if len(sub_parts) >= 2 and sub_parts[0].isdigit():\n",
    "                try:\n",
    "                    reps = int(sub_parts[0])\n",
    "                    exercise = \" \".join(sub_parts[1:])\n",
    "                    # Simple check if exercise is in our known exercises (can be improved)\n",
    "                    if exercise in self.evaluator.mappings['exercise_to_idx']:\n",
    "                         commands.append((reps, exercise))\n",
    "                    else:\n",
    "                         print(f\"Warning: Exercise '{exercise}' not recognized.\")\n",
    "                         self._speak(f\"Sorry, I don't recognize the exercise {exercise}.\")\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse repetitions from '{part}'.\")\n",
    "                    self._speak(\"Sorry, I didn't understand the number of repetitions in your command.\")\n",
    "            else:\n",
    "                 print(f\"Warning: Could not parse command part '{part}'. Expected 'number exercise'.\")\n",
    "                 self._speak(\"Sorry, I didn't understand the format of your command.\")\n",
    "\n",
    "        return commands\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        # Variables pour estimation de niveau\n",
    "        confidence_buffer = []\n",
    "        WINDOW_SIZE = 30\n",
    "        last_spoken_exercise = None\n",
    "        last_spoken_correction = None\n",
    "        # command_active = False # Flag to indicate if a voice command is active - managed by current_command now\n",
    "        # command_exercise = None # Exercise specified by voice command\n",
    "        # command_reps = 0 # Repetitions specified by voice command\n",
    "        # current_reps = 0 # Counter for repetitions performed - managed by current_command_reps_completed now\n",
    "\n",
    "\n",
    "        # Démarrage de la capture vidéo\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Impossible d'ouvrir la webcam\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Display instruction for voice command\n",
    "            command_prompt = \"Press 'c' and say 'reps exercise (then reps exercise)'\"\n",
    "            cv2.putText(frame, command_prompt, (10, frame.shape[0] - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            # Listen for a voice command when 'c' is pressed\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                self._speak(\"Listening for command...\")\n",
    "                command_string = self._listen_command()\n",
    "                if command_string:\n",
    "                     parsed_commands = self._parse_command(command_string)\n",
    "                     if parsed_commands:\n",
    "                         self.command_queue.extend(parsed_commands)\n",
    "                         if not self.current_command: # Start the first command if none is active\n",
    "                             self.current_command = self.command_queue.pop(0)\n",
    "                             self.current_command_reps_completed = 0\n",
    "                             self._speak(f\"Starting workout: {self.current_command[0]} {self.current_command[1]}s.\")\n",
    "                     else:\n",
    "                         self._speak(\"No valid commands received.\")\n",
    "                else:\n",
    "                    self._speak(\"Could not understand your command.\")\n",
    "\n",
    "\n",
    "            # Prédiction et corrections\n",
    "            ex, grp, conf, corrs = self._process_frame(frame)\n",
    "\n",
    "            # Update current exercise and group for display if no command is active\n",
    "            if not self.current_command and ex:\n",
    "                self.current_ex = ex\n",
    "                self.current_grp = grp\n",
    "\n",
    "\n",
    "            if ex: # ex here is either the predicted or commanded exercise\n",
    "                # Mise à jour du buffer de confiance\n",
    "                confidence_buffer.append(conf)\n",
    "                if len(confidence_buffer) > WINDOW_SIZE:\n",
    "                    confidence_buffer.pop(0)\n",
    "                avg_conf = np.mean(confidence_buffer)\n",
    "\n",
    "                # Estimation simple du niveau\n",
    "                if avg_conf >= 0.85:\n",
    "                    level = \"expert\"\n",
    "                elif avg_conf >= 0.70:\n",
    "                    level = \"intermediate\"\n",
    "                else:\n",
    "                    level = \"novice\"\n",
    "\n",
    "                # Update user level in the corrector instance\n",
    "                self.user_level = level\n",
    "\n",
    "                # Announce exercise or correction based on command state\n",
    "                if self.current_command:\n",
    "                    commanded_reps, commanded_exercise = self.current_command\n",
    "                    # Repetition tracking (Placeholder - needs actual movement detection logic)\n",
    "                    # This is where you would add logic to detect a completed repetition\n",
    "                    # and increment self.current_command_reps_completed.\n",
    "                    # For demonstration, let's simulate completing a rep on space bar press\n",
    "                    if key == ord(' '):\n",
    "                         self.current_command_reps_completed += 1\n",
    "                         self._speak(f\"Repetition {self.current_command_reps_completed} of {commanded_reps}.\")\n",
    "                         if self.current_command_reps_completed >= commanded_reps:\n",
    "                              self._speak(f\"Completed {commanded_reps} {commanded_exercise}s.\")\n",
    "                              if self.command_queue:\n",
    "                                  self.current_command = self.command_queue.pop(0)\n",
    "                                  self.current_command_reps_completed = 0\n",
    "                                  self._speak(f\"Next exercise: {self.current_command[0]} {self.current_command[1]}s.\")\n",
    "                              else:\n",
    "                                  self._speak(\"Workout complete!\")\n",
    "                                  self.current_command = None # End of workout\n",
    "                                  self.current_command_reps_completed = 0\n",
    "\n",
    "\n",
    "                if corrs and corrs[0]['message'] != last_spoken_correction:\n",
    "                     # Only speak corrections if a command is active or if no command is active and an exercise is detected\n",
    "                     if self.current_command or (not self.current_command and ex):\n",
    "                          self._speak(corrs[0]['message']) # Speak the first correction\n",
    "                          last_spoken_correction = corrs[0]['message']\n",
    "                elif ex != last_spoken_exercise and not self.current_command: # Announce new detected exercise only if no command is active\n",
    "                     self._speak(f\"Exercice détecté : {ex}\")\n",
    "                     last_spoken_exercise = ex\n",
    "                     last_spoken_correction = None # Reset correction spoken when exercise changes\n",
    "\n",
    "\n",
    "\n",
    "            # Dessin des informations et corrections\n",
    "            annotated = self._draw(frame, corrs)\n",
    "            cv2.imshow('Analyse Niveau', annotated)\n",
    "\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "exercise_points = mappings[\"exercise_points\"]\n",
    "group_mapping  = mappings[\"group_mapping\"]\n",
    "# Initialisation de l’évaluateur de modèle\n",
    "evaluator = ModelEvaluator(\n",
    "    model_path=CHECKPOINT_PATH,\n",
    "    mappings_path=MAPPINGS_PATH,\n",
    "    device='cpu'\n",
    ")                                                                                    # [3]\n",
    "\n",
    "\n",
    "# Instanciation du correcteur webcam\n",
    "wc = WebcamCorrector(evaluator=evaluator, user_level='novice')\n",
    "\n",
    "# 3. Démarrer la boucle\n",
    "wc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51e552-b2ab-4a82-b104-62b135b25b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17268\\4238669975.py:190: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import torch\n",
    "import json\n",
    "import speech_recognition as sr # Import the speech_recognition library\n",
    "\n",
    "\n",
    "class PoseClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_groups, num_exercises):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                           bidirectional=True,\n",
    "                           num_layers=2,\n",
    "                           dropout=0.3)\n",
    "\n",
    "        # Attention Temporelle\n",
    "        self.attention = nn.MultiheadAttention(2*hidden_dim, 4)\n",
    "\n",
    "        # Branches Spécialisées\n",
    "        self.group_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_groups)\n",
    "        )\n",
    "\n",
    "        self.exercise_net = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_exercises)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # [batch, seq, 2*hidden]\n",
    "        out = out.permute(1, 0, 2)  # [seq, batch, 2*hidden]\n",
    "\n",
    "        # Mécanisme d'Attention\n",
    "        attn_out, _ = self.attention(out, out, out)\n",
    "        pooled = torch.mean(attn_out, dim=0)  # [batch, 2*hidden]\n",
    "\n",
    "        group = self.group_net(pooled)\n",
    "        exercise = self.exercise_net(pooled)\n",
    "\n",
    "        return group, exercise\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Charge un modèle PyTorch entraîné et ses mappings JSON,\n",
    "    puis fournit une méthode `predict` pour déduire le groupe et l’exercice.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, mappings_path, device='cpu'):\n",
    "        self.device = device\n",
    "        # Lecture des mappings JSON (idx_to_group, idx_to_exercise, dims)\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "        # Instanciation du modèle avec les dimensions sauvegardées\n",
    "        self.model = PoseClassificationModel(\n",
    "            input_dim   = self.mappings['input_dim'],\n",
    "            hidden_dim  = self.mappings['hidden_dim'],\n",
    "            num_groups      = self.mappings['num_groups'],\n",
    "            num_exercises   = self.mappings['num_exercises']\n",
    "        ).to(self.device)\n",
    "        # Chargement du checkpoint PyTorch\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, sequence_tensor):\n",
    "        \"\"\"\n",
    "        Prédit le groupe, l’exercice et la confiance pour une séquence de features.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            grp_out, ex_out = self.model(sequence_tensor)\n",
    "        grp_idx = grp_out.argmax(dim=1).item()\n",
    "        ex_idx  = ex_out.argmax(dim=1).item()\n",
    "        confidence = float(torch.softmax(ex_out, dim=1).max())\n",
    "        group    = self.mappings['idx_to_group'][str(grp_idx)]\n",
    "        exercise = self.mappings['idx_to_exercise'][str(ex_idx)]\n",
    "        return group, exercise, confidence\n",
    "\n",
    "    def _load_model_and_mappings(self, model_path, mappings_path):\n",
    "        \"\"\"Charge le meilleur modèle sauvegardé et ses mappings\"\"\"\n",
    "        # Charger les mappings\n",
    "        with open(mappings_path, 'r') as f:\n",
    "            self.mappings = json.load(f)\n",
    "\n",
    "    def _calculate_biomech_metrics(self, sequences):\n",
    "        \"\"\"Calcule les métriques biomécaniques pour une séquence\"\"\"\n",
    "        # Simulation des métriques - à remplacer par votre logique réelle\n",
    "        return {\n",
    "            'angle_accuracy': np.random.uniform(0.7, 0.95),\n",
    "            'movement_quality': np.random.uniform(0.6, 0.9),\n",
    "            'stability_score': np.random.uniform(0.5, 0.85)\n",
    "        }\n",
    "\n",
    "    def generate_evaluation_report(self, results):\n",
    "        \"\"\"Génère un rapport détaillé d'évaluation\"\"\"\n",
    "        total_samples = sum(len(class_results) for class_results in results.values())\n",
    "        total_exercise_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['exercise_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "        total_group_correct = sum(\n",
    "            sum(1 for sample in class_results if sample['group_correct'])\n",
    "            for class_results in results.values()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📈 RAPPORT d'ÉVALUATION GLOBAL\")\n",
    "        print(f\"=\" * 50)\n",
    "        print(f\"Échantillons analysés: {total_samples}\")\n",
    "        print(f\"Précision exercices: {total_exercise_correct/total_samples:.2%}\")\n",
    "        print(f\"Précision groupes: {total_group_correct/total_samples:.2%}\")\n",
    "\n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'exercise_accuracy': total_exercise_correct/total_samples,\n",
    "            'group_accuracy': total_group_correct/total_samples,\n",
    "            'detailed_results': results\n",
    "        }\n",
    "CHECKPOINT_PATH = \"pose_model_best.pth\"\n",
    "MAPPINGS_PATH = \"model_mappings3.json\"\n",
    "\n",
    "with open(\"model_mappings3.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "\n",
    "class WebcamCorrector:\n",
    "    def __init__(self, evaluator, user_level='intermediate'):\n",
    "        self.evaluator = evaluator\n",
    "        self.user_level = user_level\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.drawing = mp.solutions.drawing_utils\n",
    "        self.tts = pyttsx3.init()\n",
    "        self.tts.setProperty('rate', 150)\n",
    "        self.tts.setProperty('volume', 0.8)\n",
    "        self.sequence, self.max_len = [], 30\n",
    "        self.current_ex = None\n",
    "        self.max_feature_dim = evaluator.mappings['input_dim'] # Get expected input dimension from model mappings\n",
    "        self.standards = AdaptiveExerciseStandards() # Initialize AdaptiveExerciseStandards\n",
    "        self.recognizer = sr.Recognizer() # Initialize speech recognizer\n",
    "        self.command_queue = [] # To store list of (reps, exercise) tuples\n",
    "        self.current_command = None # To store the current (reps, exercise) tuple being guided\n",
    "        self.current_command_reps_completed = 0 # To track completed reps for the current command\n",
    "\n",
    "\n",
    "    def _extract_features(self, lm):\n",
    "        coords = [coord for p in lm.landmark for coord in (p.x, p.y, p.z)]\n",
    "        angles = self._compute_angles(lm)\n",
    "        dists  = self._compute_distances(lm)\n",
    "        features = np.array(coords + angles + dists, dtype=np.float32)\n",
    "\n",
    "        # Pad features to match the expected input dimension of the model\n",
    "        if features.shape[0] < self.max_feature_dim:\n",
    "            padding = self.max_feature_dim - features.shape[0]\n",
    "            features = np.pad(features, (0, padding), 'constant', constant_values=0)\n",
    "        elif features.shape[0] > self.max_feature_dim:\n",
    "            features = features[:self.max_feature_dim]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def _process_frame(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = self.pose.process(rgb)\n",
    "        corrs = []\n",
    "        predicted_ex = None # Store the predicted exercise separately\n",
    "\n",
    "        if res.pose_landmarks:\n",
    "            self.drawing.draw_landmarks(frame, res.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n",
    "            features = self._extract_features(res.pose_landmarks)\n",
    "            self.sequence.append(features)\n",
    "            if len(self.sequence) > self.max_len:\n",
    "                self.sequence.pop(0)\n",
    "\n",
    "            if len(self.sequence) >= 15:\n",
    "                seq_tensor = torch.tensor(self.sequence, dtype=torch.float32).unsqueeze(0).to(self.evaluator.device)\n",
    "                grp, predicted_ex, conf = self.evaluator.predict(seq_tensor)\n",
    "\n",
    "                # If a command is active, use the commanded exercise for corrections\n",
    "                if self.current_command:\n",
    "                     commanded_reps, commanded_exercise = self.current_command\n",
    "                     corrs = self._generate_corrections(commanded_exercise, self.user_level)\n",
    "                     return commanded_exercise, grp, conf, corrs # Return commanded exercise\n",
    "\n",
    "                else:\n",
    "                    # Otherwise, use the predicted exercise for corrections\n",
    "                    corrs = self._generate_corrections(predicted_ex, self.user_level)\n",
    "                    return predicted_ex, grp, conf, corrs # Return predicted exercise\n",
    "\n",
    "        return None, None, 0.0, corrs # Return None for exercise if no landmarks\n",
    "\n",
    "\n",
    "    def _compute_angles(self, lm):\n",
    "        def angle(a, b, c):\n",
    "            v1, v2 = a - b, c - b\n",
    "            cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cosang, -1, 1)))\n",
    "        idxs = [(12,14,16), (11,13,15), (24,26,28), (23,25,27)]  # 4 angles\n",
    "        pts = lm.landmark\n",
    "        return [angle(np.array([pts[i].x, pts[i].y]),\n",
    "                      np.array([pts[j].x, pts[j].y]),\n",
    "                      np.array([pts[k].x, pts[k].y]))\n",
    "                for i,j,k in idxs]\n",
    "\n",
    "    def _compute_distances(self, lm):\n",
    "        pts = lm.landmark\n",
    "        sl, sr = np.array([pts[11].x, pts[11].y]), np.array([pts[12].x, pts[12].y])\n",
    "        hl, hr = np.array([pts[23].x, pts[23].y]), np.array([pts[24].x, pts[24].y])\n",
    "        nose, hipc = np.array([pts[0].x, pts[0].y]), (hl + hr) / 2\n",
    "        return [np.linalg.norm(sr - sl),\n",
    "                np.linalg.norm(hr - hl),\n",
    "                np.linalg.norm(nose - hipc)]\n",
    "\n",
    "    def _generate_corrections(self, exercise, user_level):\n",
    "        \"\"\"Generate corrections based on exercise and user level.\"\"\"\n",
    "        # This is a placeholder. In a real application, you would analyze the\n",
    "        # biomechanical data (angles, distances, etc.) from the 'features'\n",
    "        # variable to determine specific errors and generate corrections\n",
    "        # using the AdaptiveExerciseStandards class.\n",
    "        # For now, we'll just return some generic corrections for demonstration.\n",
    "        if exercise in self.standards.exercise_standards:\n",
    "            # Simulate detecting some common errors based on user level\n",
    "            errors = []\n",
    "            if user_level == 'novice':\n",
    "                errors = ['back_not_straight', 'not_low_enough'] # Example novice errors\n",
    "            elif user_level == 'intermediate':\n",
    "                 errors = ['arms_too_wide', 'body_not_straight'] # Example intermediate errors\n",
    "            elif user_level == 'expert':\n",
    "                 errors = ['back_not_straight'] # Example expert errors\n",
    "\n",
    "            corrections = []\n",
    "            for error_type in errors:\n",
    "                 correction_message = self.standards.get_adaptive_correction(exercise, error_type, user_level)\n",
    "                 corrections.append({'message': correction_message, 'severity': 'medium'}) # Simulate medium severity\n",
    "\n",
    "            if not corrections and exercise in ['squat', 'push-up', 'deadlift']:\n",
    "                 # Add a progression tip if no specific errors are detected for these exercises\n",
    "                 progression_tip = self.standards.get_adaptive_correction(exercise, 'progression_tip', user_level)\n",
    "                 if progression_tip:\n",
    "                     corrections.append({'message': progression_tip, 'severity': 'low'})\n",
    "\n",
    "            return corrections\n",
    "\n",
    "        return []\n",
    "\n",
    "    def _draw(self, frame, corrs):\n",
    "        \"\"\"Superpose l’overlay, le niveau utilisateur et les corrections.\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        overlay = frame.copy()\n",
    "        # Adjust overlay height to accommodate command info\n",
    "        cv2.rectangle(overlay, (5,5), (w-5,165), (0,0,0), -1)\n",
    "        frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)\n",
    "        y = 30\n",
    "        cv2.putText(frame, f\"Niveau: {self.user_level}\", (10,y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "        if self.current_command:\n",
    "            commanded_reps, commanded_exercise = self.current_command\n",
    "            cv2.putText(frame, f\"Commande: {commanded_reps} {commanded_exercise}\", (10, y + 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Reps: {self.current_command_reps_completed}/{commanded_reps}\", (10, y + 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            y += 60 # Adjust starting y for corrections\n",
    "\n",
    "        elif self.current_ex: # Display predicted exercise if no command is active\n",
    "             cv2.putText(frame, f\"Exercice: {self.current_ex}\", (10,y+30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "             cv2.putText(frame, f\"Groupe: {self.current_grp}\", (10,y+60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "             y += 60 # Adjust starting y for corrections\n",
    "\n",
    "\n",
    "        for c in corrs[:3]:\n",
    "            y += 25\n",
    "            color = (0,0,255) if c.get('severity','low')=='high' else (0,165,255)\n",
    "            cv2.putText(frame, c['message'], (10,y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        return frame\n",
    "\n",
    "    def _speak(self, text):\n",
    "        \"\"\"Synthétise et prononce un texte.\"\"\"\n",
    "        try:\n",
    "            self.tts.say(text)\n",
    "            self.tts.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during text-to-speech: {e}\")\n",
    "\n",
    "    def _listen_command(self):\n",
    "        \"\"\"Listens for a voice command from the microphone and transcribes it.\"\"\"\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something!\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1) # Adjust for noise\n",
    "            audio = self.recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = self.recognizer.recognize_google(audio, language=\"en-US\") # You can change the language if needed\n",
    "            print(f\"You said: {command}\")\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_command(self, command_string):\n",
    "        \"\"\"Parses a command string like '10 squat then 20 deadlift' into a list of (reps, exercise) tuples.\"\"\"\n",
    "        commands = []\n",
    "        # Handle both \"reps exercise\" and \"reps:exercise\" formats, and \"then\" separator\n",
    "        parts = command_string.lower().replace(':', ' ').split(\" then \")\n",
    "        for part in parts:\n",
    "            sub_parts = part.split()\n",
    "            if len(sub_parts) >= 2 and sub_parts[0].isdigit():\n",
    "                try:\n",
    "                    reps = int(sub_parts[0])\n",
    "                    exercise = \" \".join(sub_parts[1:])\n",
    "                    # Simple check if exercise is in our known exercises (can be improved)\n",
    "                    if exercise in self.evaluator.mappings['exercise_to_idx']:\n",
    "                         commands.append((reps, exercise))\n",
    "                    else:\n",
    "                         print(f\"Warning: Exercise '{exercise}' not recognized.\")\n",
    "                         self._speak(f\"Sorry, I don't recognize the exercise {exercise}.\")\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse repetitions from '{part}'.\")\n",
    "                    self._speak(\"Sorry, I didn't understand the number of repetitions in your command.\")\n",
    "            else:\n",
    "                 print(f\"Warning: Could not parse command part '{part}'. Expected 'number exercise'.\")\n",
    "                 self._speak(\"Sorry, I didn't understand the format of your command.\")\n",
    "\n",
    "        return commands\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        # Variables pour estimation de niveau\n",
    "        confidence_buffer = []\n",
    "        WINDOW_SIZE = 30\n",
    "        last_spoken_exercise = None\n",
    "        last_spoken_correction = None\n",
    "        # command_active = False # Flag to indicate if a voice command is active - managed by current_command now\n",
    "        # command_exercise = None # Exercise specified by voice command\n",
    "        # command_reps = 0 # Repetitions specified by voice command\n",
    "        # current_reps = 0 # Counter for repetitions performed - managed by current_command_reps_completed now\n",
    "\n",
    "\n",
    "        # Démarrage de la capture vidéo\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Impossible d'ouvrir la webcam\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Display instruction for voice/text command\n",
    "            command_prompt = \"Press 'c' for voice command ('reps exercise (then reps exercise)') or 'g' for text ('reps:exercise, reps:exercise,...')\"\n",
    "            cv2.putText(frame, command_prompt, (10, frame.shape[0] - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                self._speak(\"Listening for voice command...\")\n",
    "                command_string = self._listen_command()\n",
    "                if command_string:\n",
    "                     parsed_commands = self._parse_command(command_string)\n",
    "                     if parsed_commands:\n",
    "                         self.command_queue.extend(parsed_commands)\n",
    "                         if not self.current_command: # Start the first command if none is active\n",
    "                             self.current_command = self.command_queue.pop(0)\n",
    "                             self.current_command_reps_completed = 0\n",
    "                             self._speak(f\"Starting workout: {self.current_command[0]} {self.current_command[1]}s.\")\n",
    "                     else:\n",
    "                         self._speak(\"No valid commands received.\")\n",
    "                else:\n",
    "                    self._speak(\"Could not understand your voice command.\")\n",
    "            elif key == ord('g'):\n",
    "                 # Text input via console (blocking)\n",
    "                 cv2.destroyAllWindows() # Close video window temporarily\n",
    "                 print(\"\\nEnter workout command (e.g., '10:squat, 20:deadlift'):\")\n",
    "                 command_string = input()\n",
    "                 # Re-open video window\n",
    "                 cv2.namedWindow('Analyse Niveau', cv2.WINDOW_NORMAL)\n",
    "                 cv2.imshow('Analyse Niveau', frame) # Show last frame\n",
    "                 if command_string:\n",
    "                      # Parse text command\n",
    "                      parsed_commands = []\n",
    "                      parts = command_string.lower().split(',')\n",
    "                      for part in parts:\n",
    "                           sub_parts = part.strip().split(':')\n",
    "                           if len(sub_parts) == 2 and sub_parts[0].isdigit():\n",
    "                               try:\n",
    "                                    reps = int(sub_parts[0])\n",
    "                                    exercise = sub_parts[1].strip()\n",
    "                                    if exercise in self.evaluator.mappings['exercise_to_idx']:\n",
    "                                         parsed_commands.append((reps, exercise))\n",
    "                                    else:\n",
    "                                         print(f\"Warning: Exercise '{exercise}' not recognized.\")\n",
    "                                         self._speak(f\"Sorry, I don't recognize the exercise {exercise}.\")\n",
    "                               except ValueError:\n",
    "                                    print(f\"Warning: Could not parse repetitions from '{part}'.\")\n",
    "                                    self._speak(\"Sorry, I didn't understand the number of repetitions in your command.\")\n",
    "                           else:\n",
    "                                print(f\"Warning: Could not parse command part '{part}'. Expected 'number:exercise'.\")\n",
    "                                self._speak(\"Sorry, I didn't understand the format of your command.\")\n",
    "\n",
    "                      if parsed_commands:\n",
    "                          self.command_queue.extend(parsed_commands)\n",
    "                          if not self.current_command: # Start the first command if none is active\n",
    "                              self.current_command = self.command_queue.pop(0)\n",
    "                              self.current_command_reps_completed = 0\n",
    "                              self._speak(f\"Starting workout: {self.current_command[0]} {self.current_command[1]}s.\")\n",
    "                      else:\n",
    "                          self._speak(\"No valid commands received.\")\n",
    "                 else:\n",
    "                     self._speak(\"No command entered.\")\n",
    "\n",
    "\n",
    "\n",
    "            # Prédiction et corrections\n",
    "            ex, grp, conf, corrs = self._process_frame(frame)\n",
    "\n",
    "            # Update current exercise and group for display if no command is active\n",
    "            if not self.current_command and ex:\n",
    "                self.current_ex = ex\n",
    "                self.current_grp = grp\n",
    "\n",
    "\n",
    "            if ex: # ex here is either the predicted or commanded exercise\n",
    "                # Mise à jour du buffer de confiance\n",
    "                confidence_buffer.append(conf)\n",
    "                if len(confidence_buffer) > WINDOW_SIZE:\n",
    "                    confidence_buffer.pop(0)\n",
    "                avg_conf = np.mean(confidence_buffer)\n",
    "\n",
    "                # Estimation simple du niveau\n",
    "                if avg_conf >= 0.85:\n",
    "                    level = \"expert\"\n",
    "                elif avg_conf >= 0.70:\n",
    "                    level = \"intermediate\"\n",
    "                else:\n",
    "                    level = \"novice\"\n",
    "\n",
    "                # Update user level in the corrector instance\n",
    "                self.user_level = level\n",
    "\n",
    "                # Annonce exercise or correction based on command state\n",
    "                if self.current_command:\n",
    "                    commanded_reps, commanded_exercise = self.current_command\n",
    "                    # Repetition tracking (Placeholder - needs actual movement detection logic)\n",
    "                    # This is where you would add logic to detect a completed repetition\n",
    "                    # and increment self.current_command_reps_completed.\n",
    "                    # For demonstration, let's simulate completing a rep on space bar press\n",
    "                    if key == ord(' '):\n",
    "                         self.current_command_reps_completed += 1\n",
    "                         self._speak(f\"Repetition {self.current_command_reps_completed} of {commanded_reps}.\")\n",
    "                         if self.current_command_reps_completed >= commanded_reps:\n",
    "                              self._speak(f\"Completed {commanded_reps} {commanded_exercise}s.\")\n",
    "                              if self.command_queue:\n",
    "                                  self.current_command = self.command_queue.pop(0)\n",
    "                                  self.current_command_reps_completed = 0\n",
    "                                  self._speak(f\"Next exercise: {self.current_command[0]} {self.current_command[1]}s.\")\n",
    "                              else:\n",
    "                                  self._speak(\"Workout complete!\")\n",
    "                                  self.current_command = None # End of workout\n",
    "                                  self.current_command_reps_completed = 0\n",
    "\n",
    "\n",
    "                if corrs and corrs[0]['message'] != last_spoken_correction:\n",
    "                     # Only speak corrections if a command is active or if no command is active and an exercise is detected\n",
    "                     if self.current_command or (not self.current_command and ex):\n",
    "                          self._speak(corrs[0]['message']) # Speak the first correction\n",
    "                          last_spoken_correction = corrs[0]['message']\n",
    "                elif ex != last_spoken_exercise and not self.current_command: # Announce new detected exercise only if no command is active\n",
    "                     self._speak(f\"Exercice détecté : {ex}\")\n",
    "                     last_spoken_exercise = ex\n",
    "                     last_spoken_correction = None # Reset correction spoken when exercise changes\n",
    "\n",
    "\n",
    "\n",
    "            # Dessin des informations et corrections\n",
    "            annotated = self._draw(frame, corrs)\n",
    "            cv2.imshow('Analyse Niveau', annotated)\n",
    "\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "exercise_points = mappings[\"exercise_points\"]\n",
    "group_mapping  = mappings[\"group_mapping\"]\n",
    "# Initialisation de l’évaluateur de modèle\n",
    "evaluator = ModelEvaluator(\n",
    "    model_path=CHECKPOINT_PATH,\n",
    "    mappings_path=MAPPINGS_PATH,\n",
    "    device='cpu'\n",
    ")                                                                                    # [3]\n",
    "\n",
    "\n",
    "# Instanciation du correcteur webcam\n",
    "wc = WebcamCorrector(evaluator=evaluator, user_level='novice')\n",
    "\n",
    "# 3. Démarrer la boucle\n",
    "wc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c3393-2a9b-4313-83e5-ad0662a55092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e57ebb-e112-4cbe-97ec-622d68d9c2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
